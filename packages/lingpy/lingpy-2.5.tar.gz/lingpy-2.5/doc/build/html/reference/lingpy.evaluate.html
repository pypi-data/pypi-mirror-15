<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>lingpy.evaluate package &mdash; LingPy</title>
    
    <link rel="stylesheet" href="../_static/lingpy.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '2.5',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="top" title="LingPy" href="../index.html" />
<link rel="stylesheet" type="text/css" href="_static/handheld.css" media="screen and (max-device-width: 720px)" />

  </head>
  <body role="document">
<div style="color: black;background-color: white; font-size: 3.2em; text-align: left; padding: 15px 10px 10px 15px">
LingPy
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
	<li><a href="../index.html">Home</a> |&nbsp;</li>
	<li><a href="../news.html">News</a> |&nbsp;</li>
	<li><a href="../intro.html">Introduction</a> |&nbsp;</li>
	<li><a href="../examples.html">Examples</a> |&nbsp;</li>
	<li><a href="../tutorial/index.html">Tutorial</a> |&nbsp;</li>
	<li><a href="../docu/index.html">Documentation</a> |&nbsp;</li>
	<li><a href="modules.html">Reference</a> |&nbsp;</li>
        <li><a href="../download.html">Download </a> </li>

 
      </ul>
    </div>

  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="lingpy-evaluate-package">
<h1>lingpy.evaluate package<a class="headerlink" href="#lingpy-evaluate-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-lingpy.evaluate.acd">
<span id="lingpy-evaluate-acd-module"></span><h2>lingpy.evaluate.acd module<a class="headerlink" href="#module-lingpy.evaluate.acd" title="Permalink to this headline">¶</a></h2>
<p>Evaluation methods for automatic cognate detection.</p>
<dl class="function">
<dt id="lingpy.evaluate.acd.bcubes">
<code class="descclassname">lingpy.evaluate.acd.</code><code class="descname">bcubes</code><span class="sig-paren">(</span><em>wordlist</em>, <em>gold='cogid'</em>, <em>test='lexstatid'</em>, <em>modify_ref=False</em>, <em>pprint=True</em>, <em>per_concept=False</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.acd.bcubes" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute B-Cubed scores for test and reference datasets.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>lex</strong> : <a class="reference internal" href="lingpy.basic.html#lingpy.basic.wordlist.Wordlist" title="lingpy.basic.wordlist.Wordlist"><code class="xref py py-class docutils literal"><span class="pre">lingpy.basic.wordlist.Wordlist</span></code></a></p>
<blockquote>
<div><p>A <a class="reference internal" href="lingpy.basic.html#lingpy.basic.wordlist.Wordlist" title="lingpy.basic.wordlist.Wordlist"><code class="xref py py-class docutils literal"><span class="pre">lingpy.basic.wordlist.Wordlist</span></code></a> class or a daughter class,
(like the <a class="reference internal" href="lingpy.compare.html#lingpy.compare.lexstat.LexStat" title="lingpy.compare.lexstat.LexStat"><code class="xref py py-class docutils literal"><span class="pre">LexStat</span></code></a> class used for the
computation). It should have two columns indicating cognate IDs.</p>
</div></blockquote>
<p><strong>gold</strong> : str (default=&#8217;cogid&#8217;)</p>
<blockquote>
<div><p>The name of the column containing the gold standard cognate
assignments.</p>
</div></blockquote>
<p><strong>test</strong> : str (default=&#8217;lexstatid&#8217;)</p>
<blockquote>
<div><p>The name of the column containing the automatically implemented cognate
assignments.</p>
</div></blockquote>
<p><strong>modify_ref</strong> : function (default=False)</p>
<blockquote>
<div><p>Use a function to modify the reference. If your cognate identifiers
are numerical, for example, and negative values are assigned as
loans, but you want to suppress this behaviour, just set this
keyword to &#8220;abs&#8221;, and all cognate IDs will be converted to their
absolute value.</p>
</div></blockquote>
<p><strong>pprint</strong> : bool (default=True)</p>
<blockquote>
<div><p>Print out the results</p>
</div></blockquote>
<p><strong>per_concept</strong> : bool (default=False)</p>
<blockquote>
<div><p>Compute b-cubed scores per concep and not for the whole data in one
piece.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>t</strong> : tuple</p>
<blockquote class="last">
<div><p>A tuple consisting of the precision, the recall, and the harmonic mean
(F-scores).</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference internal" href="#lingpy.evaluate.acd.diff" title="lingpy.evaluate.acd.diff"><code class="xref py py-obj docutils literal"><span class="pre">diff</span></code></a>, <a class="reference internal" href="#lingpy.evaluate.acd.pairs" title="lingpy.evaluate.acd.pairs"><code class="xref py py-obj docutils literal"><span class="pre">pairs</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>B-Cubed scores were first described by <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Bagga1998"><span class="pre">Bagga1998</span></a></code> as part of an
algorithm. Later on, <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Amigo2009"><span class="pre">Amigo2009</span></a></code> showed that they can also used as
to compare cluster decisions. <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Hauer2011"><span class="pre">Hauer2011</span></a></code> applied the B-Cubed
scores first to the task of automatic cognate detection.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.evaluate.acd.diff">
<code class="descclassname">lingpy.evaluate.acd.</code><code class="descname">diff</code><span class="sig-paren">(</span><em>wordlist</em>, <em>gold='cogid'</em>, <em>test='lexstatid'</em>, <em>modify_ref=False</em>, <em>pprint=True</em>, <em>filename=''</em>, <em>tofile=True</em>, <em>transcription='ipa'</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.acd.diff" title="Permalink to this definition">¶</a></dt>
<dd><p>Write differences in classifications on an item-basis to file.</p>
<dl class="docutils">
<dt>lex</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier"><a class="reference internal" href="lingpy.compare.html#lingpy.compare.lexstat.LexStat" title="lingpy.compare.lexstat.LexStat"><code class="xref py py-class docutils literal"><span class="pre">lingpy.compare.lexstat.LexStat</span></code></a></span><dd>The <a class="reference internal" href="lingpy.compare.html#lingpy.compare.lexstat.LexStat" title="lingpy.compare.lexstat.LexStat"><code class="xref py py-class docutils literal"><span class="pre">LexStat</span></code></a> class used for the
computation. It should have two columns indicating cognate IDs.</dd>
<dt>gold</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str (default=&#8217;cogid&#8217;)</span><dd>The name of the column containing the gold standard cognate
assignments.</dd>
<dt>test</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str (default=&#8217;lexstatid&#8217;)</span><dd>The name of the column containing the automatically implemented cognate
assignments.</dd>
<dt>modify_ref</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">function (default=False)</span><dd>Use a function to modify the reference. If your cognate identifiers
are numerical, for example, and negative values are assigned as
loans, but you want to suppress this behaviour, just set this
keyword to &#8220;abs&#8221;, and all cognate IDs will be converted to their
absolute value.</dd>
<dt>pprint</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">bool (default=True)</span><dd>Print out the results</dd>
<dt>filename</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str (default=&#8217;&#8216;)</span><dd>Name of the output file. If not specified, it is identical with the
name of the <a class="reference internal" href="lingpy.compare.html#lingpy.compare.lexstat.LexStat" title="lingpy.compare.lexstat.LexStat"><code class="xref py py-class docutils literal"><span class="pre">LexStat</span></code></a>, but with the
extension <code class="docutils literal"><span class="pre">diff</span></code>.</dd>
<dt>tofile</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">bool (default=True)</span><dd>If set to c{False}, no data will be written to file, but instead, the
data will be returned.</dd>
<dt>transcription</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str (default=&#8221;ipa&#8221;)</span><dd>The file in which the transcriptions are located (should be a string,
no segmentized version, for convenience of writing to file).</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>t</strong> : tuple</p>
<blockquote class="last">
<div><p>A nested tuple consisting of two further tuples. The first
containing precision, recall, and harmonic mean
(F-scores), the second containing the same values for the pair-scores.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference internal" href="#lingpy.evaluate.acd.bcubes" title="lingpy.evaluate.acd.bcubes"><code class="xref py py-obj docutils literal"><span class="pre">bcubes</span></code></a>, <a class="reference internal" href="#lingpy.evaluate.acd.pairs" title="lingpy.evaluate.acd.pairs"><code class="xref py py-obj docutils literal"><span class="pre">pairs</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>If the <strong>tofile</strong> option is chosen, the results are written to a specific
file with the extension <code class="docutils literal"><span class="pre">diff</span></code>. This file contains all cognate sets in
which there are differences between gold standard and test sets. It also
gives detailed information regarding false positives, false negatives, and
the words involved in these wrong decisions.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.evaluate.acd.npoint_ap">
<code class="descclassname">lingpy.evaluate.acd.</code><code class="descname">npoint_ap</code><span class="sig-paren">(</span><em>scores</em>, <em>cognates</em>, <em>reverse=False</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.acd.npoint_ap" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the n-point average precision.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>scores</strong> : list</p>
<blockquote>
<div><p>The scores of your algorithm for pairwise string comparison.</p>
</div></blockquote>
<p><strong>cognates</strong> : list</p>
<blockquote>
<div><p>The cognate codings of the word pairs you compared. 1 indicates that
the pair is cognate, 0 indicates that it is not cognate.</p>
</div></blockquote>
<p><strong>reverse</strong> : bool (default=False)</p>
<blockquote class="last">
<div><p>The order of your ranking mechanism. If your algorithm yields high
scores for words which are probably cognate, and low scores for
non-cognate words, you should set this keyword to &#8220;True&#8221;.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>This follows the description in <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Kondrak2002"><span class="pre">Kondrak2002</span></a></code>. The n-point average
precision is useful to compare the discriminative force of different
algorithms for string similarity, or to train the parameters of a given
algorithm.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cognates</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">lingpy.evaluate.acd</span> <span class="k">import</span> <span class="n">npoint_ap</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">npoint_ap</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">cognates</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="lingpy.evaluate.acd.pairs">
<code class="descclassname">lingpy.evaluate.acd.</code><code class="descname">pairs</code><span class="sig-paren">(</span><em>lex</em>, <em>gold='cogid'</em>, <em>test='lexstatid'</em>, <em>modify_ref=False</em>, <em>pprint=True</em>, <em>_return_string=False</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.acd.pairs" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute pair scores for the evaluation of cognate detection algorithms.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>lex</strong> : <a class="reference internal" href="lingpy.compare.html#lingpy.compare.lexstat.LexStat" title="lingpy.compare.lexstat.LexStat"><code class="xref py py-class docutils literal"><span class="pre">lingpy.compare.lexstat.LexStat</span></code></a></p>
<blockquote>
<div><p>The <a class="reference internal" href="lingpy.compare.html#lingpy.compare.lexstat.LexStat" title="lingpy.compare.lexstat.LexStat"><code class="xref py py-class docutils literal"><span class="pre">LexStat</span></code></a> class used for the
computation. It should have two columns indicating cognate IDs.</p>
</div></blockquote>
<p><strong>gold</strong> : str (default=&#8217;cogid&#8217;)</p>
<blockquote>
<div><p>The name of the column containing the gold standard cognate
assignments.</p>
</div></blockquote>
<p><strong>test</strong> : str (default=&#8217;lexstatid&#8217;)</p>
<blockquote>
<div><p>The name of the column containing the automatically implemented cognate
assignments.</p>
</div></blockquote>
<p><strong>modify_ref</strong> : function (default=False)</p>
<blockquote>
<div><p>Use a function to modify the reference. If your cognate identifiers
are numerical, for example, and negative values are assigned as
loans, but you want to suppress this behaviour, just set this
keyword to &#8220;abs&#8221;, and all cognate IDs will be converted to their
absolute value.</p>
</div></blockquote>
<p><strong>pprint</strong> : bool (default=True)</p>
<blockquote>
<div><p>Print out the results</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>t</strong> : tuple</p>
<blockquote class="last">
<div><p>A tuple consisting of the precision, the recall, and the harmonic mean
(F-scores).</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference internal" href="#lingpy.evaluate.acd.diff" title="lingpy.evaluate.acd.diff"><code class="xref py py-obj docutils literal"><span class="pre">diff</span></code></a>, <a class="reference internal" href="#lingpy.evaluate.acd.bcubes" title="lingpy.evaluate.acd.bcubes"><code class="xref py py-obj docutils literal"><span class="pre">bcubes</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>Pair-scores can be computed in different ways, with often different
results. This variant follows the description by <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Bouchard-Cote2013"><span class="pre">Bouchard-Cote2013</span></a></code>.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.evaluate.acd.partial_bcubes">
<code class="descclassname">lingpy.evaluate.acd.</code><code class="descname">partial_bcubes</code><span class="sig-paren">(</span><em>wordlist</em>, <em>gold</em>, <em>test</em>, <em>pprint=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.acd.partial_bcubes" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute B-Cubed scores for test and reference datasets for partial cognate            detection.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>wordlist</strong> : <a class="reference internal" href="lingpy.basic.html#lingpy.basic.wordlist.Wordlist" title="lingpy.basic.wordlist.Wordlist"><code class="xref py py-class docutils literal"><span class="pre">Wordlist</span></code></a></p>
<blockquote>
<div><p>A <a class="reference internal" href="lingpy.basic.html#lingpy.basic.wordlist.Wordlist" title="lingpy.basic.wordlist.Wordlist"><code class="xref py py-class docutils literal"><span class="pre">Wordlist</span></code></a>, or one of it&#8217;s daughter
classes (like, e.g., the <a class="reference internal" href="lingpy.compare.html#lingpy.compare.partial.Partial" title="lingpy.compare.partial.Partial"><code class="xref py py-class docutils literal"><span class="pre">Partial</span></code></a>
class used for computation of partial cognates. It should have two
columns indicating cognate IDs.</p>
</div></blockquote>
<p><strong>gold</strong> : str (default=&#8217;cogid&#8217;)</p>
<blockquote>
<div><p>The name of the column containing the gold standard cognate
assignments.</p>
</div></blockquote>
<p><strong>test</strong> : str (default=&#8217;lexstatid&#8217;)</p>
<blockquote>
<div><p>The name of the column containing the automatically implemented cognate
assignments.</p>
</div></blockquote>
<p><strong>pprint</strong> : bool (default=True)</p>
<blockquote>
<div><p>Print out the results</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>t</strong> : tuple</p>
<blockquote class="last">
<div><p>A tuple consisting of the precision, the recall, and the harmonic mean
(F-scores).</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference internal" href="#lingpy.evaluate.acd.bcubes" title="lingpy.evaluate.acd.bcubes"><code class="xref py py-obj docutils literal"><span class="pre">bcubes</span></code></a>, <a class="reference internal" href="#lingpy.evaluate.acd.diff" title="lingpy.evaluate.acd.diff"><code class="xref py py-obj docutils literal"><span class="pre">diff</span></code></a>, <a class="reference internal" href="#lingpy.evaluate.acd.pairs" title="lingpy.evaluate.acd.pairs"><code class="xref py py-obj docutils literal"><span class="pre">pairs</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>B-Cubed scores were first described by <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Bagga1998"><span class="pre">Bagga1998</span></a></code> as part of an
algorithm. Later on, <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Amigo2009"><span class="pre">Amigo2009</span></a></code> showed that they can also used as
to compare cluster decisions. <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Hauer2011"><span class="pre">Hauer2011</span></a></code> applied the B-Cubed
scores first to the task of automatic cognate detection.</p>
</dd></dl>

</div>
<div class="section" id="module-lingpy.evaluate.alr">
<span id="lingpy-evaluate-alr-module"></span><h2>lingpy.evaluate.alr module<a class="headerlink" href="#module-lingpy.evaluate.alr" title="Permalink to this headline">¶</a></h2>
<p>Module provides methods for the evaluation of automatic linguistic reconstruction analyses.</p>
<dl class="function">
<dt id="lingpy.evaluate.alr.mean_edit_distance">
<code class="descclassname">lingpy.evaluate.alr.</code><code class="descname">mean_edit_distance</code><span class="sig-paren">(</span><em>wordlist</em>, <em>gold='proto'</em>, <em>test='consensus'</em>, <em>ref='cogid'</em>, <em>tokens=True</em>, <em>classes=False</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.alr.mean_edit_distance" title="Permalink to this definition">¶</a></dt>
<dd><p>Function computes the edit distance between gold standard and test set.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>wordlist</strong> : ~lingpy.basic.wordlist.Wordlist</p>
<blockquote>
<div><p>The wordlist object containing the data for a given analysis.</p>
</div></blockquote>
<p><strong>gold</strong> : str (default=&#8221;proto&#8221;)</p>
<blockquote>
<div><p>The name of the column containing the gold-standard solutions.</p>
</div></blockquote>
<p><strong>test = &#8220;consensus&#8221;</strong> :</p>
<blockquote>
<div><p>The name of the column containing the test solutions.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>dist</strong> : float</p>
<blockquote class="last">
<div><p>The mean edit distance between gold and test reconstructions.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>This function has an alias (&#8220;med&#8221;). Calling it will produce the same
results.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.evaluate.alr.med">
<code class="descclassname">lingpy.evaluate.alr.</code><code class="descname">med</code><span class="sig-paren">(</span><em>wordlist</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.alr.med" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-lingpy.evaluate.apa">
<span id="lingpy-evaluate-apa-module"></span><h2>lingpy.evaluate.apa module<a class="headerlink" href="#module-lingpy.evaluate.apa" title="Permalink to this headline">¶</a></h2>
<p>Basic module for the comparison of automatic phonetic alignments.</p>
<dl class="class">
<dt id="lingpy.evaluate.apa.Eval">
<em class="property">class </em><code class="descclassname">lingpy.evaluate.apa.</code><code class="descname">Eval</code><span class="sig-paren">(</span><em>gold</em>, <em>test</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.Eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="http://docs.python.org/library/functions.html#object" title="(in Python v2.7)"><code class="xref py py-class docutils literal"><span class="pre">object</span></code></a></p>
<p>Base class for evaluation objects.</p>
</dd></dl>

<dl class="class">
<dt id="lingpy.evaluate.apa.EvalMSA">
<em class="property">class </em><code class="descclassname">lingpy.evaluate.apa.</code><code class="descname">EvalMSA</code><span class="sig-paren">(</span><em>gold</em>, <em>test</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalMSA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingpy.evaluate.apa.Eval" title="lingpy.evaluate.apa.Eval"><code class="xref py py-class docutils literal"><span class="pre">lingpy.evaluate.apa.Eval</span></code></a></p>
<p>Base class for the evaluation of automatic multiple sequence analyses.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>gold, test</strong> : <a class="reference internal" href="lingpy.align.html#lingpy.align.sca.MSA" title="lingpy.align.sca.MSA"><code class="xref py py-class docutils literal"><span class="pre">MSA</span></code></a></p>
<blockquote class="last">
<div><p>The <code class="xref py py-class docutils literal"><span class="pre">Multiple</span></code> objects which shall be
compared. The first object should be the gold standard and the second
object should be the test set.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>Most of the scores which can be calculated with help of this class are standard
evaluation scores in evolutionary biology. For a close description on how
these scores are calculated, see, for example, <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Thompson1999"><span class="pre">Thompson1999</span></a></code>,
<code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=List2012"><span class="pre">List2012</span></a></code>, and <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Rosenberg2009b"><span class="pre">Rosenberg2009b</span></a></code>.</p>
<dl class="method">
<dt id="lingpy.evaluate.apa.EvalMSA.c_score">
<code class="descname">c_score</code><span class="sig-paren">(</span><em>mode=1</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalMSA.c_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the column (C) score.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>mode</strong> : { 1, 2, 3, 4 }</p>
<blockquote>
<div><p>Indicate, which mode to compute. Select between:</p>
<ol class="arabic simple">
<li>divide the number of common columns in reference and test
alignment by the total number of columns in the test alignment
(the traditional C score described in <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Thompson1999"><span class="pre">Thompson1999</span></a></code>,
also known as &#8220;precision&#8221; score in applications of information
retrieval),</li>
<li>divide the number of common columns in reference and test
alignment by the total number of columns in the reference
alignment (also known as &#8220;recall&#8221; score in applications of
information retrieval),</li>
<li>divide the number of common columns in reference and test
alignment by the average number of columns in reference and test
alignment, or</li>
<li>combine the scores of mode <code class="docutils literal"><span class="pre">1</span></code> and mode <code class="docutils literal"><span class="pre">2</span></code> by computing
their F-score, using the formula <img class="math" src="../_images/math/8adf729d042071eca0031f550cfc2ade9da347eb.png" alt="2 * \frac{pr}{p+r}"/>,
where <em>p</em> is the precision (mode <code class="docutils literal"><span class="pre">1</span></code>) and <em>r</em> is the recall
(mode <code class="docutils literal"><span class="pre">2</span></code>).</li>
</ol>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>score</strong> : float</p>
<blockquote class="last">
<div><p>The C score for reference and test alignments.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The different c-</p>
</dd></dl>

<dl class="attribute">
<dt id="lingpy.evaluate.apa.EvalMSA.c_scores">
<code class="descname">c_scores</code><em class="property"> = None</em><a class="headerlink" href="#lingpy.evaluate.apa.EvalMSA.c_scores" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="lingpy.evaluate.apa.EvalMSA.check_swaps">
<code class="descname">check_swaps</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalMSA.check_swaps" title="Permalink to this definition">¶</a></dt>
<dd><p>Check for possibly identical swapped sites.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>swap</strong> : { -2, -1, 0, 1, 2 }</p>
<blockquote class="last">
<div><p>Information regarding the identity of swap decisions is coded by
integers, whereas</p>
<dl class="docutils">
<dt>1 &#8211; indicates that swaps are detected in both gold standard and</dt>
<dd><p class="first last">testset, whereas a negative value indicates that the positions
are not identical,</p>
</dd>
<dt>2 &#8211; indicates that swap decisions are not identical in gold</dt>
<dd><p class="first last">standard and testset, whereas a negative value indicates that
there is a false positive in the testset, and</p>
</dd>
<dt>0 &#8211; indicates that there are no swaps in the gold standard and the</dt>
<dd><p class="first last">testset.</p>
</dd>
</dl>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lingpy.evaluate.apa.EvalMSA.jc_score">
<code class="descname">jc_score</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalMSA.jc_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the Jaccard (JC) score.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>score</strong> : float</p>
<blockquote class="last">
<div><p>The JC score.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><code class="xref py py-obj docutils literal"><span class="pre">lingpy.test.evaluate.EvalPSA.jc_score</span></code></p>
</div>
<p class="rubric">Notes</p>
<p>The Jaccard score (see <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=List2012"><span class="pre">List2012</span></a></code>) is calculated by dividing the size of
the intersection of residue pairs in reference and test alignment by
the size of the union of residue pairs in reference and test alignment.</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.evaluate.apa.EvalMSA.r_score">
<code class="descname">r_score</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalMSA.r_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the rows (R) score.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>score</strong> : float</p>
<blockquote class="last">
<div><p>The PIR score.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The R score is the number of identical rows (sequences) in reference and test
alignment divided by the total number of rows.</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.evaluate.apa.EvalMSA.sp_score">
<code class="descname">sp_score</code><span class="sig-paren">(</span><em>mode=1</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalMSA.sp_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the sum-of-pairs (SP) score.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>mode</strong> : { 1, 2, 3 }</p>
<blockquote>
<div><p>Indicate, which mode to compute. Select between:</p>
<ol class="arabic simple">
<li>divide the number of common residue pairs in reference and test
alignment by the total number of residue pairs in the test
alignment (the traditional SP score described in
<code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Thompson1999"><span class="pre">Thompson1999</span></a></code>, also known as &#8220;precision&#8221; score in
applications of information retrieval),</li>
<li>divide the number of common residue pairs in reference and test
alignment by the total number of residue pairs in the reference
alignment (also known as &#8220;recall&#8221; score in applications of
information retrieval),</li>
<li>divide the number of common residue pairs in reference and test
alignment by the average number of residue pairs in reference
and test alignment.</li>
</ol>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>score</strong> : float</p>
<blockquote class="last">
<div><p>The SP score for gold standard and test alignments.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The SP score (see <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Thompson1999"><span class="pre">Thompson1999</span></a></code>) is calculated by dividing the number of
identical residue pairs in reference and test alignment by the total
number of residue pairs in the reference alignment.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lingpy.evaluate.apa.EvalPSA">
<em class="property">class </em><code class="descclassname">lingpy.evaluate.apa.</code><code class="descname">EvalPSA</code><span class="sig-paren">(</span><em>gold</em>, <em>test</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalPSA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingpy.evaluate.apa.Eval" title="lingpy.evaluate.apa.Eval"><code class="xref py py-class docutils literal"><span class="pre">lingpy.evaluate.apa.Eval</span></code></a></p>
<p>Base class for the evaluation of automatic pairwise sequence analyses.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>gold, test</strong> : <a class="reference internal" href="lingpy.align.html#lingpy.align.sca.PSA" title="lingpy.align.sca.PSA"><code class="xref py py-class docutils literal"><span class="pre">lingpy.align.sca.PSA</span></code></a></p>
<blockquote class="last">
<div><p>The <code class="xref py py-class docutils literal"><span class="pre">Pairwise</span></code> objects which shall be
compared. The first object should be the gold standard and the second
object should be the test set.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>Moste of the scores which can be calculated with help of this class are standard
evaluation scores in evolutionary biology. For a close description on how
these scores are calculated, see, for example, <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Thompson1999"><span class="pre">Thompson1999</span></a></code>,
<code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=List2012"><span class="pre">List2012</span></a></code>, and <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Rosenberg2009b"><span class="pre">Rosenberg2009b</span></a></code>.</p>
<dl class="method">
<dt id="lingpy.evaluate.apa.EvalPSA.c_score">
<code class="descname">c_score</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalPSA.c_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate column (C) score.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>score</strong> : float</p>
<blockquote class="last">
<div><p>The C score for reference and test alignments.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The C score, as it is described in <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Thompson1999"><span class="pre">Thompson1999</span></a></code>, is calculated by
dividing the number of columns which are identical in the gold
standarad and the test alignment by the total number of columns in the
test alignment.</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.evaluate.apa.EvalPSA.diff">
<code class="descname">diff</code><span class="sig-paren">(</span><em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalPSA.diff" title="Permalink to this definition">¶</a></dt>
<dd><p>Write all differences between two sets to a file.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>filename</strong> : str (default=&#8217;eval_psa_diff&#8217;)</p>
<blockquote class="last">
<div><p>Default</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lingpy.evaluate.apa.EvalPSA.jc_score">
<code class="descname">jc_score</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalPSA.jc_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the Jaccard (JC) score.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>score</strong> : float</p>
<blockquote class="last">
<div><p>The JC score.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The Jaccard score (see <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=List2012"><span class="pre">List2012</span></a></code>) is calculated by dividing the size of
the intersection of residue pairs in reference and test alignment by
the size of the union of residue pairs in reference and test alignment.</p>
</dd></dl>

<dl class="attribute">
<dt id="lingpy.evaluate.apa.EvalPSA.pairwise_column_scores">
<code class="descname">pairwise_column_scores</code><em class="property"> = None</em><a class="headerlink" href="#lingpy.evaluate.apa.EvalPSA.pairwise_column_scores" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="lingpy.evaluate.apa.EvalPSA.r_score">
<code class="descname">r_score</code><span class="sig-paren">(</span><em>mode=1</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalPSA.r_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the percentage of identical rows (PIR) score.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>mode</strong> : { 1, 2 }</p>
<blockquote>
<div><p>Select between mode <code class="docutils literal"><span class="pre">1</span></code>, where all sequences are compared with
each other, and mode <code class="docutils literal"><span class="pre">2</span></code>, where only whole alignments are
compared.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>score</strong> : float</p>
<blockquote class="last">
<div><p>The PIR score.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The PIR score is the number of identical rows (sequences) in reference and test
alignment divided by the total number of rows.</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.evaluate.apa.EvalPSA.sp_score">
<code class="descname">sp_score</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.evaluate.apa.EvalPSA.sp_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the sum-of-pairs (SP) score.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>score</strong> : float</p>
<blockquote class="last">
<div><p>The SP score for reference and test alignments.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The SP score (see <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Thompson1999"><span class="pre">Thompson1999</span></a></code>) is calculated by dividing the number of
identical residue pairs in reference and test alignment by the total
number of residue pairs in the reference alignment.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-lingpy.evaluate">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-lingpy.evaluate" title="Permalink to this headline">¶</a></h2>
<p>Basic module for the evaluation of algorithms.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/lingpy-logo.svg" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">lingpy.evaluate package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-lingpy.evaluate.acd">lingpy.evaluate.acd module</a></li>
<li><a class="reference internal" href="#module-lingpy.evaluate.alr">lingpy.evaluate.alr module</a></li>
<li><a class="reference internal" href="#module-lingpy.evaluate.apa">lingpy.evaluate.apa module</a></li>
<li><a class="reference internal" href="#module-lingpy.evaluate">Module contents</a></li>
</ul>
</li>
</ul>

  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/reference/lingpy.evaluate.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
	<li><a href="../index.html">Home</a> |&nbsp;</li>
	<li><a href="../news.html">News</a> |&nbsp;</li>
	<li><a href="../intro.html">Introduction</a> |&nbsp;</li>
	<li><a href="../examples.html">Examples</a> |&nbsp;</li>
	<li><a href="../tutorial/index.html">Tutorial</a> |&nbsp;</li>
	<li><a href="../docu/index.html">Documentation</a> |&nbsp;</li>
	<li><a href="modules.html">Reference</a> |&nbsp;</li>
        <li><a href="../download.html">Download </a> </li>

 
      </ul>
    </div>
 <div id="footer" style="align-items:center;padding-top:5px;padding-left:0px;display:flex;justify-content:space-between;">

   <div>
     <a href="http://ssh.mpg.de"><img width="60px" src="../_static/minerva.png" alt="MPG-SSH" /></a>
   </div>
  <div>
    <a href="http://dfg.de/"><img width="80px" src="../_static/dfg_logo_schwarz.jpg" alt="DFG" /></a>
  </div>

  <div style="max-width:300px;">
    <p style="font-size:70%">Created using <a href="http://sphinx-doc.org">Sphinx</a>. Last updated
    on May 17, 2016<br>
      This work is licensed under a <a rel="license"
        href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_US">Creative
      Commons Attribution-NonCommercial 3.0 Unported License</a>.</p>
    <p>
      <a rel="license" href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_US">
        <img alt="Creative Commons License" style="border-width:0;width:100px;"
		    src="http://i.creativecommons.org/l/by-nc/3.0/88x31.png" /></a> </p>
  </div>

  <div>
    <a href="http://erc.europa.eu/"><img width="80px" src="http://quanthistling.info/theme/qhl/images/logo_erc.png" alt="ERC" /></a>
  </div>
  <div style="max-width:150px;text-align:right;">
    <a href="http://github.com/lingpy/lingpy/">Application source on</a> 
    <a href="https://github.com/"><img width="100px" src="../_static/GitHub_Logo.png" alt="github logo" /></a>
</div>
</div>

  </body>
</html>