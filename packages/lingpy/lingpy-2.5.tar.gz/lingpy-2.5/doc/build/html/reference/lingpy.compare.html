<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>lingpy.compare package &mdash; LingPy</title>
    
    <link rel="stylesheet" href="../_static/lingpy.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '2.5',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="top" title="LingPy" href="../index.html" />
<link rel="stylesheet" type="text/css" href="_static/handheld.css" media="screen and (max-device-width: 720px)" />

  </head>
  <body role="document">
<div style="color: black;background-color: white; font-size: 3.2em; text-align: left; padding: 15px 10px 10px 15px">
LingPy
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
	<li><a href="../index.html">Home</a> |&nbsp;</li>
	<li><a href="../news.html">News</a> |&nbsp;</li>
	<li><a href="../intro.html">Introduction</a> |&nbsp;</li>
	<li><a href="../examples.html">Examples</a> |&nbsp;</li>
	<li><a href="../tutorial/index.html">Tutorial</a> |&nbsp;</li>
	<li><a href="../docu/index.html">Documentation</a> |&nbsp;</li>
	<li><a href="modules.html">Reference</a> |&nbsp;</li>
        <li><a href="../download.html">Download </a> </li>

 
      </ul>
    </div>

  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="lingpy-compare-package">
<h1>lingpy.compare package<a class="headerlink" href="#lingpy-compare-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-lingpy.compare.lexstat">
<span id="lingpy-compare-lexstat-module"></span><h2>lingpy.compare.lexstat module<a class="headerlink" href="#module-lingpy.compare.lexstat" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="lingpy.compare.lexstat.LexStat">
<em class="property">class </em><code class="descclassname">lingpy.compare.lexstat.</code><code class="descname">LexStat</code><span class="sig-paren">(</span><em>filename</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.lexstat.LexStat" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingpy.basic.html#lingpy.basic.wordlist.Wordlist" title="lingpy.basic.wordlist.Wordlist"><code class="xref py py-class docutils literal"><span class="pre">lingpy.basic.wordlist.Wordlist</span></code></a></p>
<p>Basic class for automatic cognate detection.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>filename</strong> : str</p>
<blockquote>
<div><p>The name of the file that shall be loaded.</p>
</div></blockquote>
<p><strong>model</strong> : <a class="reference internal" href="lingpy.data.html#lingpy.data.model.Model" title="lingpy.data.model.Model"><code class="xref py py-class docutils literal"><span class="pre">Model</span></code></a></p>
<blockquote>
<div><p>The sound-class model that shall be used for the analysis. Defaults to
the SCA sound-class model.</p>
</div></blockquote>
<p><strong>merge_vowels</strong> : bool (default=True)</p>
<blockquote>
<div><p>Indicate whether consecutive vowels should be merged into single tokens or kept
apart as separate tokens.</p>
</div></blockquote>
<p><strong>transform</strong> : dict</p>
<blockquote>
<div><p>A dictionary that indicates how prosodic strings should be simplified
(or generally transformed), using a simple key-value structure with the
key referring to the original prosodic context and the value to the new
value.
Currently, prosodic strings (see
<a class="reference internal" href="lingpy.sequence.html#lingpy.sequence.sound_classes.prosodic_string" title="lingpy.sequence.sound_classes.prosodic_string"><code class="xref py py-meth docutils literal"><span class="pre">prosodic_string()</span></code></a>) offer 11
different prosodic contexts. Since not all these are helpful in
preliminary analyses for cognate detection, it is useful to merge some
of these contexts into one. The default settings distinguish only 5
instead of 11 available contexts, namely:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">C</span></code> for all consonants in prosodically ascending position,</li>
<li><code class="docutils literal"><span class="pre">c</span></code> for all consonants in prosodically descending position,</li>
<li><code class="docutils literal"><span class="pre">V</span></code> for all vowels,</li>
<li><code class="docutils literal"><span class="pre">T</span></code> for all tones, and</li>
<li><code class="docutils literal"><span class="pre">_</span></code> for word-breaks.</li>
</ul>
<p>Make sure to check also the &#8220;vowel&#8221; keyword when initialising a LexStat
object, since the symbols you use for vowels and tones should be
identical with the ones you define in your transform dictionary.</p>
</div></blockquote>
<p><strong>vowels</strong> : str (default=&#8221;<a href="#id1"><span class="problematic" id="id2">VT_</span></a>&#8221;)</p>
<blockquote>
<div><p>For scoring function creation using the
<a class="reference internal" href="#lingpy.compare.lexstat.LexStat.get_scorer" title="lingpy.compare.lexstat.LexStat.get_scorer"><code class="xref py py-class docutils literal"><span class="pre">get_scorer</span></code></a> function, you have the
possibility to use reduced scores for the matching of tones and vowels
by modifying the &#8220;vscale&#8221; parameter, which is set to 0.5 as a default.
In order to make sure that vowels and tones are properly detected, make
sure your prosodic string representation of vowels matches the one in
this keyword. Thus, if you change the prosodic strings using the
&#8220;transform&#8221; keyword, you also need to change the vowel string, to make
sure that &#8220;vscale&#8221; works as wanted in the
<a class="reference internal" href="#lingpy.compare.lexstat.LexStat.get_scorer" title="lingpy.compare.lexstat.LexStat.get_scorer"><code class="xref py py-class docutils literal"><span class="pre">get_scorer</span></code></a> function.</p>
</div></blockquote>
<p><strong>check</strong> : bool (default=False)</p>
<blockquote>
<div><p>If set to <strong>True</strong>, the input file will first be checked for errors
before the calculation is carried out. Errors will be written to the
file <strong>errors</strong>, defaulting to <code class="docutils literal"><span class="pre">errors.log</span></code>. See also <code class="docutils literal"><span class="pre">apply_checks</span></code></p>
</div></blockquote>
<p><strong>apply_checks</strong> : bool (default=False)</p>
<blockquote>
<div><p>If set to <strong>True</strong>, any errors identified by <cite>check</cite> will be handled
silently.</p>
</div></blockquote>
<p><strong>no_bscorer: bool (default=False)</strong> :</p>
<blockquote>
<div><p>If set to <strong>True</strong>, this will suppress the creation of a
language-specific scoring function (which may become quite large and is
additional ballast if the method &#8220;lexstat&#8221; is not used after all. If
you use the &#8220;lexstat&#8221; method, however, this needs to be set to
<strong>False</strong>.</p>
</div></blockquote>
<p><strong>errors</strong> : str</p>
<blockquote class="last">
<div><p>The name of the error log.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>Instantiating this class does not require a lot of parameters. However,
the user may modify its behaviour by providing additional attributes in the
input file.</p>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="3%" />
<col width="17%" />
<col width="80%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>pairs</td>
<td>dict</td>
<td>A dictionary with tuples of language names as key and indices as value,         pointing to unique combinations of words with the same meaning in all         language pairs.</td>
</tr>
<tr class="row-even"><td>model</td>
<td><a class="reference internal" href="lingpy.data.html#lingpy.data.model.Model" title="lingpy.data.model.Model"><code class="xref py py-class docutils literal"><span class="pre">Model</span></code></a></td>
<td>The sound class model instance which serves to convert the phonetic
data into sound classes.</td>
</tr>
<tr class="row-odd"><td>chars</td>
<td>list</td>
<td><p class="first">A list of all unique language-specific character types in the
instantiated LexStat object. The characters in this list consist of</p>
<ul class="simple">
<li>the language identifier (numeric, referenced as &#8220;langid&#8221; as a
default, but customizable via the keyword &#8220;langid&#8221;)</li>
<li>the sound class symbol for the respective IPA transcription value</li>
<li>the prosodic class value</li>
</ul>
<p class="last">All values are represented in the above order as one string, separated
by a dot. Gaps are also included in this collection. They are
traditionally represented as &#8220;X&#8221; for the sound class and &#8220;-&#8221; for the
prosodic string.</p>
</td>
</tr>
<tr class="row-even"><td>rchars</td>
<td>list</td>
<td>A list containing all unique character types across languages. In
contrast to the chars-attribute, the &#8220;rchars&#8221; (raw chars) do not
contain the language identifier, thus they only consist of two values,
separated by a dot, namely, the sound class symbol, and the prosodic
class value.</td>
</tr>
<tr class="row-odd"><td>scorer</td>
<td>dict</td>
<td><p class="first">A collection of <a class="reference internal" href="lingpy.algorithm.cython.html#lingpy.algorithm.cython.misc.ScoreDict" title="lingpy.algorithm.cython.misc.ScoreDict"><code class="xref py py-class docutils literal"><span class="pre">ScoreDict</span></code></a>
objects, which are used to score the strings. LexStat distinguishes two
different scoring functions:</p>
<ul class="last simple">
<li>rscorer: A &#8220;raw&#8221; scorer that is not language-specific and consists
only of sound class values and prosodic string values. This scorer is
traditionally used to carry out the first alignment in order to
calculate the language-specific scorer. It is directly accessible as an
attribute of the LexStat class
(<code class="xref py py-class docutils literal"><span class="pre">rscorer</span></code>). The characters
which constitute the values in this scorer are accessible via the
&#8220;rchars&#8221; attribue of each lexstat class.</li>
<li>bscorer: The language-specific scorer. This scorer is made of unique
language-specific characters. These are accessible via the &#8220;chars&#8221;
attribute of each LexStat class. As the &#8220;rscorer&#8221;, the &#8220;bscorer&#8221; can
also be accessed directly as an attribute of the LexStat class
(<code class="xref py py-class docutils literal"><span class="pre">bscorer</span></code>).</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="lingpy.compare.lexstat.LexStat.align_pairs">
<code class="descname">align_pairs</code><span class="sig-paren">(</span><em>idxA</em>, <em>idxB</em>, <em>concept=None</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.lexstat.LexStat.align_pairs" title="Permalink to this definition">¶</a></dt>
<dd><p>Align all or some words of a given pair of languages.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>idxA,idxB</strong> : {int, str}</p>
<blockquote>
<div><p>Use an integer to refer to the words by their unique internal ID,
use language names to select all words for a given language.</p>
</div></blockquote>
<p><strong>method</strong> : {&#8216;lexstat&#8217;,&#8217;sca&#8217;}</p>
<blockquote>
<div><p>Define the method to be used for the alignment of the words.</p>
</div></blockquote>
<p><strong>mode</strong> : {&#8216;global&#8217;,&#8217;local&#8217;,&#8217;overlap&#8217;,&#8217;dialign&#8217;} (default=&#8217;overlap&#8217;)</p>
<blockquote>
<div><p>Select the mode for the alignment analysis.</p>
</div></blockquote>
<p><strong>gop</strong> : int (default=-2)</p>
<blockquote>
<div><p>If &#8216;sca&#8217; is selected as a method, define the gap opening penalty.</p>
</div></blockquote>
<p><strong>scale</strong> : float (default=0.5)</p>
<blockquote>
<div><p>Select the scale for the gap extension penalty.</p>
</div></blockquote>
<p><strong>factor</strong> : float (default=0.3)</p>
<blockquote>
<div><p>Select the factor for extra scores for identical prosodic segments.</p>
</div></blockquote>
<p><strong>restricted_chars</strong> : str (default=&#8221;<a href="#id3"><span class="problematic" id="id4">T_</span></a>&#8221;)</p>
<blockquote>
<div><p>Select the restricted chars (boundary markers) in the prosodic
strings in order to enable secondary alignment.</p>
</div></blockquote>
<p><strong>distance</strong> : bool (default=True)</p>
<blockquote>
<div><p>If set to c{True}, return the distance instead of the similarity
score.</p>
</div></blockquote>
<p><strong>pprint</strong> : bool (default=True)</p>
<blockquote>
<div><p>If set to c{True}, print the results to the terminal.</p>
</div></blockquote>
<p><strong>return_distance</strong> : bool (default=False)</p>
<blockquote class="last">
<div><p>If set to c{True}, return the distance score, otherwise, nothing
will be returned.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.lexstat.LexStat.cluster">
<code class="descname">cluster</code><span class="sig-paren">(</span><em>method='sca'</em>, <em>cluster_method='upgma'</em>, <em>threshold=0.3</em>, <em>scale=0.5</em>, <em>factor=0.3</em>, <em>restricted_chars='_T'</em>, <em>mode='overlap'</em>, <em>gop=-2</em>, <em>restriction=''</em>, <em>ref=''</em>, <em>external_function=None</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.lexstat.LexStat.cluster" title="Permalink to this definition">¶</a></dt>
<dd><p>Function for flat clustering of words into cognate sets.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>method</strong> : {&#8216;sca&#8217;,&#8217;lexstat&#8217;,&#8217;edit-dist&#8217;,&#8217;turchin&#8217;} (default=&#8217;sca&#8217;)</p>
<blockquote>
<div><p>Select the method that shall be used for the calculation.</p>
</div></blockquote>
<p><strong>cluster_method</strong> : {&#8216;upgma&#8217;,&#8217;single&#8217;,&#8217;complete&#8217;, &#8216;mcl&#8217;} (default=&#8217;upgma&#8217;)</p>
<blockquote>
<div><p>Select the cluster method. &#8216;upgma&#8217; (<code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Sokal1958"><span class="pre">Sokal1958</span></a></code>) refers to
average linkage clustering, &#8216;mcl&#8217; refers to the &#8220;Markov Clustering
Algorithm&#8221; (<code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Dongen2000"><span class="pre">Dongen2000</span></a></code>).</p>
</div></blockquote>
<p><strong>threshold</strong> : float (default=0.3)</p>
<blockquote>
<div><p>Select the threshold for the cluster approach. If set to c{False},
an automatic threshold will be calculated by calculating the
average distance of unrelated sequences (use with care).</p>
</div></blockquote>
<p><strong>scale</strong> : float (default=0.5)</p>
<blockquote>
<div><p>Select the scale for the gap extension penalty.</p>
</div></blockquote>
<p><strong>factor</strong> : float (default=0.3)</p>
<blockquote>
<div><p>Select the factor for extra scores for identical prosodic segments.</p>
</div></blockquote>
<p><strong>restricted_chars</strong> : str (default=&#8221;<a href="#id5"><span class="problematic" id="id6">T_</span></a>&#8221;)</p>
<blockquote>
<div><p>Select the restricted chars (boundary markers) in the prosodic
strings in order to enable secondary alignment.</p>
</div></blockquote>
<p><strong>mode</strong> : {&#8216;global&#8217;,&#8217;local&#8217;,&#8217;overlap&#8217;,&#8217;dialign&#8217;} (default=&#8217;overlap&#8217;)</p>
<blockquote>
<div><p>Select the mode for the alignment analysis.</p>
</div></blockquote>
<p><strong>verbose</strong> : bool (default=False)</p>
<blockquote>
<div><p>Define whether verbose output should be used or not.</p>
</div></blockquote>
<p><strong>gop</strong> : int (default=-2)</p>
<blockquote>
<div><p>If &#8216;sca&#8217; is selected as a method, define the gap opening penalty.</p>
</div></blockquote>
<p><strong>restriction</strong> : {&#8216;cv&#8217;} (default=&#8221;&#8221;)</p>
<blockquote>
<div><p>Specify the restriction for calculations using the edit-distance.
Currently, only &#8220;cv&#8221; is supported. If <em>edit-dist</em> is selected as
<em>method</em> and <em>restriction</em> is set to <em>cv</em>, consonant-vowel matches
will be prohibited in the calculations and the edit distance will
be normalized by the length of the alignment rather than the length
of the longest sequence, as described in <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Heeringa2006"><span class="pre">Heeringa2006</span></a></code>.</p>
</div></blockquote>
<p><strong>inflation</strong> : {int, float} (default=2)</p>
<blockquote>
<div><p>Specify the inflation parameter for the use of the MCL algorithm.</p>
</div></blockquote>
<p><strong>expansion</strong> : int (default=2)</p>
<blockquote class="last">
<div><p>Specify the expansion parameter for the use of the MCL algorithm.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.lexstat.LexStat.get_distances">
<code class="descname">get_distances</code><span class="sig-paren">(</span><em>method='sca'</em>, <em>mode='overlap'</em>, <em>gop=-2</em>, <em>scale=0.5</em>, <em>factor=0.3</em>, <em>restricted_chars='T_'</em>, <em>aggregate=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.lexstat.LexStat.get_distances" title="Permalink to this definition">¶</a></dt>
<dd><p>Method calculates different distance estimates for language pairs.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>method</strong> : {&#8216;sca&#8217;,&#8217;lexstat&#8217;,&#8217;edit-dist&#8217;,&#8217;turchin&#8217;} (default=&#8217;sca&#8217;)</p>
<blockquote>
<div><p>Select the method that shall be used for the calculation.</p>
</div></blockquote>
<p><strong>runs</strong> : int (default=100)</p>
<blockquote>
<div><p>Select the number of random alignments for each language pair.</p>
</div></blockquote>
<p><strong>mode</strong> : {&#8216;global&#8217;,&#8217;local&#8217;,&#8217;overlap&#8217;,&#8217;dialign&#8217;} (default=&#8217;overlap&#8217;)</p>
<blockquote>
<div><p>Select the mode for the alignment analysis.</p>
</div></blockquote>
<p><strong>gop</strong> : int (default=-2)</p>
<blockquote>
<div><p>If &#8216;sca&#8217; is selected as a method, define the gap opening penalty.</p>
</div></blockquote>
<p><strong>scale</strong> : float (default=0.5)</p>
<blockquote>
<div><p>Select the scale for the gap extension penalty.</p>
</div></blockquote>
<p><strong>factor</strong> : float (default=0.3)</p>
<blockquote>
<div><p>Select the factor for extra scores for identical prosodic segments.</p>
</div></blockquote>
<p><strong>restricted_chars</strong> : str (default=&#8221;<a href="#id7"><span class="problematic" id="id8">T_</span></a>&#8221;)</p>
<blockquote>
<div><p>Select the restricted chars (boundary markers) in the prosodic
strings in order to enable secondary alignment.</p>
</div></blockquote>
<p><strong>aggregate</strong> : bool (default=True)</p>
<blockquote>
<div><p>Return aggregated distances in form of a distance matrix for all
taxa in the data.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>D</strong> : c{numpy.array}</p>
<blockquote class="last">
<div><p>An array with all distances calculated for each sequence pair.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.lexstat.LexStat.get_frequencies">
<code class="descname">get_frequencies</code><span class="sig-paren">(</span><em>ftype='sounds'</em>, <em>ref='tokens'</em>, <em>aggregated=False</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.lexstat.LexStat.get_frequencies" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the frequencies of a given wordlist.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>ftype: str (default=&#8217;sounds&#8217;)</strong> :</p>
<blockquote>
<div><p>The type of frequency which shall be calculated. Select between
&#8220;sounds&#8221; (type-token frequencies of sounds), and &#8220;wordlength&#8221; (average
word length per taxon or in aggregated form), or &#8220;diversity&#8221; for the diversity
index (requires that you have carried out cognate judgments, and
make sure to set the &#8220;ref&#8221; keyword to the column in which your
cognates are).</p>
</div></blockquote>
<p><strong>ref</strong> : str (default=&#8221;tokens&#8221;)</p>
<blockquote>
<div><p>The reference column, with the column for &#8220;tokens&#8221; as a default.
Make sure to modify this keyword in case you want to check for the
&#8220;diversity&#8221;.</p>
</div></blockquote>
<p><strong>aggregated</strong> : bool (default=False)</p>
<blockquote>
<div><p>Determine whether frequencies should be calculated in an aggregated
way, for all languages, or on a language-per-language basis.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>freqs</strong> : {dict, float}</p>
<blockquote class="last">
<div><p>Depending on the selection of the datatype you chose, this returns
either a dictionary containing the frequencies or a float
indicating the ratio.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.lexstat.LexStat.get_random_distances">
<code class="descname">get_random_distances</code><span class="sig-paren">(</span><em>method='lexstat'</em>, <em>runs=100</em>, <em>mode='overlap'</em>, <em>gop=-2</em>, <em>scale=0.5</em>, <em>factor=0.3</em>, <em>restricted_chars='T_'</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.lexstat.LexStat.get_random_distances" title="Permalink to this definition">¶</a></dt>
<dd><p>Method calculates randoms scores for unrelated words in a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>method</strong> : {&#8216;sca&#8217;,&#8217;lexstat&#8217;,&#8217;edit-dist&#8217;,&#8217;turchin&#8217;} (default=&#8217;sca&#8217;)</p>
<blockquote>
<div><p>Select the method that shall be used for the calculation.</p>
</div></blockquote>
<p><strong>runs</strong> : int (default=100)</p>
<blockquote>
<div><p>Select the number of random alignments for each language pair.</p>
</div></blockquote>
<p><strong>mode</strong> : {&#8216;global&#8217;,&#8217;local&#8217;,&#8217;overlap&#8217;,&#8217;dialign&#8217;} (default=&#8217;overlap&#8217;)</p>
<blockquote>
<div><p>Select the mode for the alignment analysis.</p>
</div></blockquote>
<p><strong>gop</strong> : int (default=-2)</p>
<blockquote>
<div><p>If &#8216;sca&#8217; is selected as a method, define the gap opening penalty.</p>
</div></blockquote>
<p><strong>scale</strong> : float (default=0.5)</p>
<blockquote>
<div><p>Select the scale for the gap extension penalty.</p>
</div></blockquote>
<p><strong>factor</strong> : float (default=0.3)</p>
<blockquote>
<div><p>Select the factor for extra scores for identical prosodic segments.</p>
</div></blockquote>
<p><strong>restricted_chars</strong> : str (default=&#8221;<a href="#id9"><span class="problematic" id="id10">T_</span></a>&#8221;)</p>
<blockquote>
<div><p>Select the restricted chars (boundary markers) in the prosodic
strings in order to enable secondary alignment.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>D</strong> : c{numpy.array}</p>
<blockquote class="last">
<div><p>An array with all distances calculated for each sequence pair.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.lexstat.LexStat.get_scorer">
<code class="descname">get_scorer</code><span class="sig-paren">(</span><em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.lexstat.LexStat.get_scorer" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a scoring function based on sound correspondences.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>method</strong> : str (default=&#8217;shuffle&#8217;)</p>
<blockquote>
<div><p>Select between &#8220;markov&#8221;, for automatically generated random
strings, and &#8220;shuffle&#8221;, for random strings taken directly from the
data.</p>
</div></blockquote>
<p><strong>ratio</strong> : tuple (default=3,2)</p>
<blockquote>
<div><p>Define the ratio between derived and original score for
sound-matches.</p>
</div></blockquote>
<p><strong>vscale</strong> : float (default=0.5)</p>
<blockquote>
<div><p>Define a scaling factor for vowels, in order to decrease their
score in the calculations.</p>
</div></blockquote>
<p><strong>runs</strong> : int (default=1000)</p>
<blockquote>
<div><p>Choose the number of random runs that shall be made in order to
derive the random distribution.</p>
</div></blockquote>
<p><strong>threshold</strong> : float (default=0.7)</p>
<blockquote>
<div><p>The threshold which used to select those words that are compared in
order to derive the attested distribution.</p>
</div></blockquote>
<p><strong>modes</strong> : list (default = [(&#8220;global&#8221;,-2,0.5),(&#8220;local&#8221;,-1,0.5)])</p>
<blockquote>
<div><p>The modes which are used in order to derive the distributions from
pairwise alignments.</p>
</div></blockquote>
<p><strong>factor</strong> : float (default=0.3)</p>
<blockquote>
<div><p>The scaling factor for sound segments with identical prosodic
environment.</p>
</div></blockquote>
<p><strong>force</strong> : bool (default=False)</p>
<blockquote>
<div><p>Force recalculation of existing distribution.</p>
</div></blockquote>
<p><strong>preprocessing: bool (default=False)</strong> :</p>
<blockquote>
<div><p>Select whether SCA-analysis shall be used to derive a preliminary
set of cognates from which the attested distribution shall be
derived.</p>
</div></blockquote>
<p><strong>rands</strong> : int (default=1000)</p>
<blockquote>
<div><p>If &#8220;method&#8221; is set to &#8220;markov&#8221;, this parameter defines the number
of strings to produce for the calculation of the random
distribution.</p>
</div></blockquote>
<p><strong>limit</strong> : int (default=10000)</p>
<blockquote>
<div><p>If &#8220;method&#8221; is set to &#8220;markov&#8221;, this parameter defines the limit
above which no more search for unique strings will be carried out.</p>
</div></blockquote>
<p><strong>cluster_method</strong> : {&#8220;upgma&#8221; &#8220;single&#8221; &#8220;complete&#8221;} (default=&#8221;upgma&#8221;)</p>
<blockquote>
<div><p>Select the method to be used for the calculation of cognates in the
preprocessing phase, if &#8220;preprocessing&#8221; is set to c{True}.</p>
</div></blockquote>
<p><strong>gop</strong> : int (default=-2)</p>
<blockquote>
<div><p>If &#8220;preprocessing&#8221; is selected, define the gap opening penalty for
the preprocessing calculation of cognates.</p>
</div></blockquote>
<p><strong>unattested</strong> : {int, float} (default=-5)</p>
<blockquote>
<div><p>If a pair of sounds is not attested in the data, but expected by
the alignment algorithm that computes the expected distribution,
the score would be -infinity. Yet in order to allow to smooth this
behaviour and to reduce the strictness, we set a default negative
value which does not necessarily need to be too high, since it may
well be that we miss a potentially good pairing in the first runs
of alignment analyses. Use this keyword to adjust this parameter.</p>
</div></blockquote>
<p><strong>unexpected</strong> : {int, float} (default=0.000001)</p>
<blockquote class="last">
<div><p>If a pair is encountered in a given alignment but not expected
according to the randomized alignments, the score would be not
calculable, since we had to divide by zero. For this reason, we set
a very small constant, by which the score is divided in this case.
Not that this constant is only relevant in those cases where the
shuffling procedure was not carried out long enough.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.lexstat.LexStat.get_subset">
<code class="descname">get_subset</code><span class="sig-paren">(</span><em>sublist</em>, <em>ref='concept'</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.lexstat.LexStat.get_subset" title="Permalink to this definition">¶</a></dt>
<dd><p>Function creates a specific subset of all word pairs.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>sublist</strong> : list</p>
<blockquote>
<div><p>A list which contains those items which should be considered for
the subset creation, for example, a list of concepts.</p>
</div></blockquote>
<p><strong>ref</strong> : string (default=&#8221;concept&#8221;)</p>
<blockquote class="last">
<div><p>The reference point to compare the given sublist.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>This function can be used to consider only a smaller part of word pairs
when creating a scorer. Normally, all words are compared, but defining
a subset allows to compare only those belonging to a specific concept
list (Swadesh list).</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.lexstat.LexStat.output">
<code class="descname">output</code><span class="sig-paren">(</span><em>fileformat</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.lexstat.LexStat.output" title="Permalink to this definition">¶</a></dt>
<dd><p>Write data to file.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>fileformat</strong> : {&#8216;tsv&#8217;, &#8216;tre&#8217;,&#8217;nwk&#8217;,&#8217;dst&#8217;, &#8216;taxa&#8217;,&#8217;starling&#8217;, &#8216;paps.nex&#8217;, &#8216;paps.csv&#8217;}</p>
<blockquote>
<div><p>The format that is written to file. This corresponds to the file
extension, thus &#8216;tsv&#8217; creates a file in tsv-format, &#8216;dst&#8217; creates
a file in Phylip-distance format, etc.</p>
</div></blockquote>
<p><strong>filename</strong> : str</p>
<blockquote>
<div><p>Specify the name of the output file (defaults to a filename that
indicates the creation date).</p>
</div></blockquote>
<p><strong>subset</strong> : bool (default=False)</p>
<blockquote>
<div><p>If set to c{True}, return only a subset of the data. Which subset
is specified in the keywords &#8216;cols&#8217; and &#8216;rows&#8217;.</p>
</div></blockquote>
<p><strong>cols</strong> : list</p>
<blockquote>
<div><p>If <em>subset</em> is set to c{True}, specify the columns that shall be
written to the csv-file.</p>
</div></blockquote>
<p><strong>rows</strong> : dict</p>
<blockquote>
<div><p>If <em>subset</em> is set to c{True}, use a dictionary consisting of keys
that specify a column and values that give a Python-statement in
raw text, such as, e.g., &#8220;== &#8216;hand&#8217;&#8221;. The content of the specified
column will then be checked against statement passed in the
dictionary, and if it is evaluated to c{True}, the respective row
will be written to file.</p>
</div></blockquote>
<p><strong>ref</strong> : str</p>
<blockquote>
<div><p>Name of the column that contains the cognate IDs if &#8216;starling&#8217; is
chosen as an output format.</p>
</div></blockquote>
<p><strong>missing</strong> : { str, int } (default=0)</p>
<blockquote>
<div><p>If &#8216;paps.nex&#8217; or &#8216;paps.csv&#8217; is chosen as fileformat, this character
will be inserted as an indicator of missing data.</p>
</div></blockquote>
<p><strong>tree_calc</strong> : {&#8216;neighbor&#8217;, &#8216;upgma&#8217;}</p>
<blockquote>
<div><p>If no tree has been calculated and &#8216;tre&#8217; or &#8216;nwk&#8217; is chosen as
output format, the method that is used to calculate the tree.</p>
</div></blockquote>
<p><strong>threshold</strong> : float (default=0.6)</p>
<blockquote>
<div><p>The threshold that is used to carry out a flat cluster analysis if
&#8216;groups&#8217; or &#8216;cluster&#8217; is chosen as output format.</p>
</div></blockquote>
<p><strong>ignore</strong> : { list, &#8220;all&#8221; }</p>
<blockquote>
<div><p>Modifies the output format in &#8220;tsv&#8221; output and allows to ignore
certain blocks in extended &#8220;tsv&#8221;, like &#8220;msa&#8221;, &#8220;taxa&#8221;, &#8220;json&#8221;, etc.,
which should be passed as a list. If you choose &#8220;all&#8221; as a plain
string and not a list, this will ignore all additional blocks and
output only plain &#8220;tsv&#8221;.</p>
</div></blockquote>
<p><strong>prettify</strong> : bool (default=True)</p>
<blockquote class="last">
<div><p>Inserts comment characters between concepts in the &#8220;tsv&#8221; file
output format, which makes it easier to see blocks of words
denoting the same concept. Switching this off will output the file
in plain &#8220;tsv&#8221;.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="lingpy.compare.lexstat.char_from_charstring">
<code class="descclassname">lingpy.compare.lexstat.</code><code class="descname">char_from_charstring</code><span class="sig-paren">(</span><em>cstring</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.lexstat.char_from_charstring" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="lingpy.compare.lexstat.get_score_dict">
<code class="descclassname">lingpy.compare.lexstat.</code><code class="descname">get_score_dict</code><span class="sig-paren">(</span><em>chars</em>, <em>model</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.lexstat.get_score_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-lingpy.compare.partial">
<span id="lingpy-compare-partial-module"></span><h2>lingpy.compare.partial module<a class="headerlink" href="#module-lingpy.compare.partial" title="Permalink to this headline">¶</a></h2>
<p>Module provides a class for partial cognate detection, expanding the LexStat class.</p>
<dl class="class">
<dt id="lingpy.compare.partial.Partial">
<em class="property">class </em><code class="descclassname">lingpy.compare.partial.</code><code class="descname">Partial</code><span class="sig-paren">(</span><em>infile</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.partial.Partial" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingpy.compare.lexstat.LexStat" title="lingpy.compare.lexstat.LexStat"><code class="xref py py-class docutils literal"><span class="pre">lingpy.compare.lexstat.LexStat</span></code></a></p>
<p>Extended class for automatic detection of partial cognates.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>filename</strong> : str</p>
<blockquote>
<div><p>The name of the file that shall be loaded.</p>
</div></blockquote>
<p><strong>model</strong> : <a class="reference internal" href="lingpy.data.html#lingpy.data.model.Model" title="lingpy.data.model.Model"><code class="xref py py-class docutils literal"><span class="pre">Model</span></code></a></p>
<blockquote>
<div><p>The sound-class model that shall be used for the analysis. Defaults to
the SCA sound-class model.</p>
</div></blockquote>
<p><strong>merge_vowels</strong> : bool (default=True)</p>
<blockquote>
<div><p>Indicate whether consecutive vowels should be merged into single tokens or kept
apart as separate tokens.</p>
</div></blockquote>
<p><strong>transform</strong> : dict</p>
<blockquote>
<div><p>A dictionary that indicates how prosodic strings should be simplified
(or generally transformed), using a simple key-value structure with the
key referring to the original prosodic context and the value to the new
value.  Currently, prosodic strings (see
<a class="reference internal" href="lingpy.sequence.html#lingpy.sequence.sound_classes.prosodic_string" title="lingpy.sequence.sound_classes.prosodic_string"><code class="xref py py-meth docutils literal"><span class="pre">prosodic_string()</span></code></a>) offer 11
different prosodic contexts. Since not all these are helpful in
preliminary analyses for cognate detection, it is useful to merge
some of these contexts into one. The default settings distinguish only
5 instead of 11 available contexts, namely:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">C</span></code> for all consonants in prosodically ascending position,</li>
<li><code class="docutils literal"><span class="pre">c</span></code> for all consonants in prosodically descending position,</li>
<li><code class="docutils literal"><span class="pre">V</span></code> for all vowels,</li>
<li><code class="docutils literal"><span class="pre">T</span></code> for all tones, and</li>
<li><code class="docutils literal"><span class="pre">_</span></code> for word-breaks.</li>
</ul>
<p>Make sure to check also the &#8220;vowel&#8221; keyword when initialising a LexStat
object, since the symbols you use for vowels and tones should be
identical with the ones you define in your transform dictionary.</p>
</div></blockquote>
<p><strong>vowels</strong> : str (default=&#8221;VT_&#8221;)</p>
<blockquote>
<div><p>For scoring function creation using the
<a class="reference internal" href="#lingpy.compare.lexstat.LexStat.get_scorer" title="lingpy.compare.lexstat.LexStat.get_scorer"><code class="xref py py-class docutils literal"><span class="pre">get_scorer</span></code></a> function, you
have the possibility to use reduced scores for the matching of tones
and vowels by modifying the &#8220;vscale&#8221; parameter, which is set to 0.5 as
a default.  In order to make sure that vowels and tones are properly
detected, make sure your prosodic string representation of vowels
matches the one in this keyword. Thus, if you change the prosodic
strings using the &#8220;transform&#8221; keyword, you also need to change the
vowel string, to make sure that &#8220;vscale&#8221; works as wanted in the
<a class="reference internal" href="#lingpy.compare.lexstat.LexStat.get_scorer" title="lingpy.compare.lexstat.LexStat.get_scorer"><code class="xref py py-class docutils literal"><span class="pre">get_scorer</span></code></a> function.</p>
</div></blockquote>
<p><strong>check</strong> : bool (default=False)</p>
<blockquote>
<div><p>If set to <strong>True</strong>, the input file will first be checked for errors
before the calculation is carried out. Errors will be written to the
file <strong>errors</strong>, defaulting to <code class="docutils literal"><span class="pre">errors.log</span></code>. See also <code class="docutils literal"><span class="pre">apply_checks</span></code></p>
</div></blockquote>
<p><strong>apply_checks</strong> : bool (default=False)</p>
<blockquote>
<div><p>If set to <strong>True</strong>, any errors identified by <cite>check</cite> will be handled
silently.</p>
</div></blockquote>
<p><strong>no_bscorer: bool (default=False)</strong> :</p>
<blockquote>
<div><p>If set to <strong>True</strong>, this will suppress the creation of a
language-specific scoring function (which may become quite large and is
additional ballast if the method &#8220;lexstat&#8221; is not used after all. If
you use the &#8220;lexstat&#8221; method, however, this needs to be set to
<strong>False</strong>.</p>
</div></blockquote>
<p><strong>errors</strong> : str</p>
<blockquote class="last">
<div><p>The name of the error log.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>This method automatically infers partial cognate sets from data which was
previously morphologically segmented.</p>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="3%" />
<col width="17%" />
<col width="80%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>pairs</td>
<td>dict</td>
<td>A dictionary with tuples of language names as key and indices as value,         pointing to unique combinations of words with the same meaning in all         language pairs.</td>
</tr>
<tr class="row-even"><td>model</td>
<td><a class="reference internal" href="lingpy.data.html#lingpy.data.model.Model" title="lingpy.data.model.Model"><code class="xref py py-class docutils literal"><span class="pre">Model</span></code></a></td>
<td>The sound class model instance which serves to convert the phonetic
data into sound classes.</td>
</tr>
<tr class="row-odd"><td>chars</td>
<td>list</td>
<td><p class="first">A list of all unique language-specific character types in the
instantiated LexStat object. The characters in this list consist of</p>
<ul class="simple">
<li>the language identifier (numeric, referenced as &#8220;langid&#8221; as a
default, but customizable via the keyword &#8220;langid&#8221;)</li>
<li>the sound class symbol for the respective IPA transcription value</li>
<li>the prosodic class value</li>
</ul>
<p class="last">All values are represented in the above order as one string, separated
by a dot. Gaps are also included in this collection. They are
traditionally represented as &#8220;X&#8221; for the sound class and &#8220;-&#8221; for the
prosodic string.</p>
</td>
</tr>
<tr class="row-even"><td>rchars</td>
<td>list</td>
<td>A list containing all unique character types across languages. In
contrast to the chars-attribute, the &#8220;rchars&#8221; (raw chars) do not
contain the language identifier, thus they only consist of two values,
separated by a dot, namely, the sound class symbol, and the prosodic
class value.</td>
</tr>
<tr class="row-odd"><td>scorer</td>
<td>dict</td>
<td><p class="first">A collection of <a class="reference internal" href="lingpy.algorithm.cython.html#lingpy.algorithm.cython.misc.ScoreDict" title="lingpy.algorithm.cython.misc.ScoreDict"><code class="xref py py-class docutils literal"><span class="pre">ScoreDict</span></code></a>
objects, which are used to score the strings. LexStat distinguishes two
different scoring functions:</p>
<ul class="last simple">
<li>rscorer: A &#8220;raw&#8221; scorer that is not language-specific and consists
only of sound class values and prosodic string values. This scorer is
traditionally used to carry out the first alignment in order to
calculate the language-specific scorer. It is directly accessible as an
attribute of the LexStat class
(<code class="xref py py-class docutils literal"><span class="pre">rscorer</span></code>). The characters
which constitute the values in this scorer are accessible via the
&#8220;rchars&#8221; attribue of each lexstat class.</li>
<li>bscorer: The language-specific scorer. This scorer is made of unique
language-specific characters. These are accessible via the &#8220;chars&#8221;
attribute of each LexStat class. As the &#8220;rscorer&#8221;, the &#8220;bscorer&#8221; can
also be accessed directly as an attribute of the LexStat class
(<code class="xref py py-class docutils literal"><span class="pre">bscorer</span></code>).</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="lingpy.compare.partial.Partial.add_cognate_ids">
<code class="descname">add_cognate_ids</code><span class="sig-paren">(</span><em>source</em>, <em>target</em>, <em>idtype='strict'</em>, <em>override=False</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.partial.Partial.add_cognate_ids" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute normal cognate identifiers from partial cognate sets.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>source: str</strong> :</p>
<blockquote>
<div><p>Name of the source column in your wordlist file.</p>
</div></blockquote>
<p><strong>target</strong> : str</p>
<blockquote>
<div><p>Name of the target column in your wordlist file.</p>
</div></blockquote>
<p><strong>idtype</strong> : str (default=&#8221;strict&#8221;)</p>
<blockquote>
<div><p>Select between &#8220;strict&#8221; and &#8220;loose&#8221;.</p>
</div></blockquote>
<p><strong>override: bool (default=False)</strong> :</p>
<blockquote class="last">
<div><p>Specify whether you want to override existing columns.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>While the computation of strict cognate IDs from partial cognate IDs is
straightforward and just judges those words as cognate which are
identical in all their parts, the computation of loose cognate IDs
constructs a network between all words, draws lines between all words
that share a common morpheme, and judges all connected components in this
network as cognate.</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.partial.Partial.partial_cluster">
<code class="descname">partial_cluster</code><span class="sig-paren">(</span><em>method='sca'</em>, <em>threshold=0.45</em>, <em>scale=0.5</em>, <em>factor=0.3</em>, <em>restricted_chars='_T'</em>, <em>mode='overlap'</em>, <em>cluster_method='infomap'</em>, <em>gop=-1</em>, <em>restriction=''</em>, <em>ref=''</em>, <em>external_function=None</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.partial.Partial.partial_cluster" title="Permalink to this definition">¶</a></dt>
<dd><p>Cluster the words into partial cognate sets.</p>
<p>Function for flat clustering of words into cognate sets.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>method</strong> : {&#8216;sca&#8217;,&#8217;lexstat&#8217;,&#8217;edit-dist&#8217;,&#8217;turchin&#8217;} (default=&#8217;sca&#8217;)</p>
<blockquote>
<div><p>Select the method that shall be used for the calculation.</p>
</div></blockquote>
<p><strong>cluster_method</strong> : {&#8216;upgma&#8217;,&#8217;single&#8217;,&#8217;complete&#8217;, &#8216;mcl&#8217;} (default=&#8217;upgma&#8217;)</p>
<blockquote>
<div><p>Select the cluster method. &#8216;upgma&#8217; (<code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Sokal1958"><span class="pre">Sokal1958</span></a></code>) refers to
average linkage clustering, &#8216;mcl&#8217; refers to the &#8220;Markov Clustering
Algorithm&#8221; (<code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Dongen2000"><span class="pre">Dongen2000</span></a></code>).</p>
</div></blockquote>
<p><strong>threshold</strong> : float (default=0.3)</p>
<blockquote>
<div><p>Select the threshold for the cluster approach. If set to c{False},
an automatic threshold will be calculated by calculating the
average distance of unrelated sequences (use with care).</p>
</div></blockquote>
<p><strong>scale</strong> : float (default=0.5)</p>
<blockquote>
<div><p>Select the scale for the gap extension penalty.</p>
</div></blockquote>
<p><strong>factor</strong> : float (default=0.3)</p>
<blockquote>
<div><p>Select the factor for extra scores for identical prosodic segments.</p>
</div></blockquote>
<p><strong>restricted_chars</strong> : str (default=&#8221;<a href="#id11"><span class="problematic" id="id12">T_</span></a>&#8221;)</p>
<blockquote>
<div><p>Select the restricted chars (boundary markers) in the prosodic
strings in order to enable secondary alignment.</p>
</div></blockquote>
<p><strong>mode</strong> : {&#8216;global&#8217;,&#8217;local&#8217;,&#8217;overlap&#8217;,&#8217;dialign&#8217;} (default=&#8217;overlap&#8217;)</p>
<blockquote>
<div><p>Select the mode for the alignment analysis.</p>
</div></blockquote>
<p><strong>verbose</strong> : bool (default=False)</p>
<blockquote>
<div><p>Define whether verbose output should be used or not.</p>
</div></blockquote>
<p><strong>gop</strong> : int (default=-2)</p>
<blockquote>
<div><p>If &#8216;sca&#8217; is selected as a method, define the gap opening penalty.</p>
</div></blockquote>
<p><strong>restriction</strong> : {&#8216;cv&#8217;} (default=&#8221;&#8221;)</p>
<blockquote>
<div><p>Specify the restriction for calculations using the edit-distance.
Currently, only &#8220;cv&#8221; is supported. If <em>edit-dist</em> is selected as
<em>method</em> and <em>restriction</em> is set to <em>cv</em>, consonant-vowel matches
will be prohibited in the calculations and the edit distance will
be normalized by the length of the alignment rather than the length
of the longest sequence, as described in <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Heeringa2006"><span class="pre">Heeringa2006</span></a></code>.</p>
</div></blockquote>
<p><strong>inflation</strong> : {int, float} (default=2)</p>
<blockquote>
<div><p>Specify the inflation parameter for the use of the MCL algorithm.</p>
</div></blockquote>
<p><strong>expansion</strong> : int (default=2)</p>
<blockquote class="last">
<div><p>Specify the expansion parameter for the use of the MCL algorithm.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-lingpy.compare.phylogeny">
<span id="lingpy-compare-phylogeny-module"></span><h2>lingpy.compare.phylogeny module<a class="headerlink" href="#module-lingpy.compare.phylogeny" title="Permalink to this headline">¶</a></h2>
<p>Phylogeny-based detection of borrowings in lexicostatistical wordlists.</p>
<dl class="class">
<dt id="lingpy.compare.phylogeny.PhyBo">
<em class="property">class </em><code class="descclassname">lingpy.compare.phylogeny.</code><code class="descname">PhyBo</code><span class="sig-paren">(</span><em>dataset</em>, <em>tree=None</em>, <em>paps='pap'</em>, <em>ref='cogid'</em>, <em>tree_calc='neighbor'</em>, <em>output_dir=None</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingpy.basic.html#lingpy.basic.wordlist.Wordlist" title="lingpy.basic.wordlist.Wordlist"><code class="xref py py-class docutils literal"><span class="pre">lingpy.basic.wordlist.Wordlist</span></code></a></p>
<p>Basic class for calculations using the TreBor method.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset</strong> : string</p>
<blockquote>
<div><p>Name of the dataset that shall be analyzed.</p>
</div></blockquote>
<p><strong>tree</strong> : {None, string}</p>
<blockquote>
<div><p>Name of the tree file.</p>
</div></blockquote>
<p><strong>paps</strong> : string (default=&#8221;pap&#8221;)</p>
<blockquote>
<div><p>Name of the column that stores the specific cognate IDs consisting
of an arbitrary integer key and a key for the concept.</p>
</div></blockquote>
<p><strong>ref</strong> : string (default=&#8221;cogid&#8221;)</p>
<blockquote>
<div><p>Name of the column that stores the general cognate ids (the
&#8220;reference&#8221; of the analysis).</p>
</div></blockquote>
<p><strong>tree_calc</strong> : {&#8216;neighbor&#8217;,&#8217;upgma&#8217;} (default=&#8217;neighbor&#8217;)</p>
<blockquote>
<div><p>Select the algorithm to be used for the tree calculation if no tree is
passed with the file.</p>
</div></blockquote>
<p><strong>missing</strong> : int (default=-1)</p>
<blockquote>
<div><p>Specify how missing data should be handled. If set to -1, missing data
can account for both presence or absence of a cognate set in the given
language. If set to 0, missing data is treated as absence.</p>
</div></blockquote>
<p><strong>degree</strong> : int (default=100)</p>
<blockquote class="last">
<div><p>The degree which is chosen for the projection of the tree layout.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.analyze">
<code class="descname">analyze</code><span class="sig-paren">(</span><em>runs='default'</em>, <em>mixed=False</em>, <em>output_gml=False</em>, <em>tar=False</em>, <em>full_analysis=True</em>, <em>plot_dists=False</em>, <em>output_plot=False</em>, <em>plot_mln=False</em>, <em>plot_msn=False</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.analyze" title="Permalink to this definition">¶</a></dt>
<dd><p>Carry out a full analysis using various parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>runs</strong> : {str list} (default=&#8221;default&#8221;)</p>
<blockquote>
<div><p>Define a couple of different models to be analyzed. Select between:</p>
<ul class="simple">
<li>&#8216;default&#8217;: weighted analysis, using parsimony and weights for
gains and losses</li>
<li>&#8216;topdown&#8217;: use the traditional approach by
<code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Nelson-Sathi2011"><span class="pre">Nelson-Sathi2011</span></a></code></li>
<li>&#8216;restriction&#8217;: use the restriction approach</li>
</ul>
<p>You can also define your own mix of models.</p>
</div></blockquote>
<p><strong>usetex</strong> : bool (default=True)</p>
<blockquote>
<div><p>Specify whether you want to use LaTeX to render plots.</p>
</div></blockquote>
<p><strong>mixed</strong> : bool (default=False)</p>
<blockquote>
<div><p>If set to c{True}, calculate a mixed model by selecting the best
model for each item separately.</p>
</div></blockquote>
<p><strong>output_gml</strong> : bool (default=False)</p>
<blockquote>
<div><p>Set to c{True} in order to output every gain-loss-scenario in
GML-format.</p>
</div></blockquote>
<p><strong>full_analysis</strong> : bool (default=True)</p>
<blockquote>
<div><p>Specifies whether a full analysis is carried out or not.</p>
</div></blockquote>
<p><strong>plot_mln</strong> : bool (default=True)</p>
<blockquote>
<div><p>Select or unselect output plot for the MLN.</p>
</div></blockquote>
<p><strong>plot_msn</strong> : bool (default=False)</p>
<blockquote class="last">
<div><p>Select or unselect output plot for the MSN.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.get_ACS">
<code class="descname">get_ACS</code><span class="sig-paren">(</span><em>glm</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.get_ACS" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the ancestral character states (ACS) for all internal nodes.</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.get_AVSD">
<code class="descname">get_AVSD</code><span class="sig-paren">(</span><em>glm</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.get_AVSD" title="Permalink to this definition">¶</a></dt>
<dd><p>Function retrieves all pap s for ancestor languages in a given tree.</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.get_CVSD">
<code class="descname">get_CVSD</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.get_CVSD" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the Contemporary Vocabulary Size Distribution (CVSD).</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.get_GLS">
<code class="descname">get_GLS</code><span class="sig-paren">(</span><em>mode='weighted'</em>, <em>ratio=(1</em>, <em>1)</em>, <em>restriction=3</em>, <em>output_gml=False</em>, <em>output_plot=False</em>, <em>tar=False</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.get_GLS" title="Permalink to this definition">¶</a></dt>
<dd><p>Create gain-loss-scenarios for all non-singleton paps in the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>mode</strong> : string (default=&#8221;weighted&#8221;)</p>
<blockquote>
<div><p>Select between &#8220;weighted&#8221;, &#8220;restriction&#8221; and &#8220;topdown&#8221;. The three
modes refer to the following frameworks:</p>
<ul class="simple">
<li>&#8220;weighted&#8221; refers to the weighted parsimony framework described in
<code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=List2014b"><span class="pre">List2014b</span></a></code> and <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=List2014a"><span class="pre">List2014a</span></a></code>.
Weights are
specified with help of a ratio for the scoring of gain and loss
events. The ratio can be defined with help of the <em>ratio</em>
keyword.</li>
<li>&#8220;restrictino&#8221; refers to a simple method in which only a
specific amount of gain events
is allowed. The maximally allowed number of gain events can be
defined with help of the <em>restriction</em> keyword.</li>
<li>&#8220;topdown&#8221; refers to the top-down method outlined in
<code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Dagan2007"><span class="pre">Dagan2007</span></a></code> and first applied to linguistic data in
<code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Nelson-Sathi2011"><span class="pre">Nelson-Sathi2011</span></a></code>. This method also defines a maximal
number of gain events, but in contrast to the &#8220;restriction&#8221;
approach, it starts from the top of the tree and stops if the
maximal number of restrictions has been reached. The maximally
allowed number of gain events can, again, be specified with help
of the <em>restriction</em> keyword.</li>
</ul>
</div></blockquote>
<p><strong>ratio</strong> : tuple (default=(1,1))</p>
<blockquote>
<div><p>If &#8220;weighted&#8221; mode is selected, define the ratio between the
weights for gains and losses.</p>
</div></blockquote>
<p><strong>restriction</strong> : int (default=3)</p>
<blockquote>
<div><p>If &#8220;restriction&#8221; is selected as mode, define the maximal number of
gains.</p>
</div></blockquote>
<p><strong>output_gml</strong> : bool (default=False)</p>
<blockquote>
<div><p>If set to c{True}, the decisions for each GLS are stored in a
separate file in GML-format.</p>
</div></blockquote>
<p><strong>tar</strong> : bool (default=False)</p>
<blockquote>
<div><p>If set to c{True}, the GML-files will be added to a compressed tar-file.</p>
</div></blockquote>
<p><strong>gpl</strong> : int (default=1)</p>
<blockquote>
<div><p>Specifies the maximal number of gains per lineage. This parameter
specifies how cases should be handled in which a character is first
gained, then lost, and then gained again. By setting this parameter
to 1 (the default setting), such cases are prohibited, since only
one gain per lineage is allowed.</p>
</div></blockquote>
<p><strong>missing_data</strong> : int (default=0)</p>
<blockquote>
<div><p>Currently, we offer two ways to handle missing data. The first case
just treats missing data in the same way in which the absence of a
character is handled and can be evoked by setting this parameter to
0. The second case will treat missing data as either absent or
present characters, based on how well each option coincides with
the overall evolutionary scenario. This behaviour can be evoked by
setting this parameter to -1.</p>
</div></blockquote>
<p><strong>push_gains: bool (default=True)</strong> :</p>
<blockquote class="last">
<div><p>In bottom-up calculations, there will often be multiple scenarios
upon which only one is selected by the method. In order to define
consistent criteria for scenario selection, we follow
<code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Mirkin2003"><span class="pre">Mirkin2003</span></a></code> in allowing to force the algorithm to prefer
those scenarios in which gains are pushed to the leaves. This
behaviour is handle by this parameter. Setting it to <em>True</em> will
force the algorithm to push gain events to the leaves of the tree.
Setting it to <em>False</em> will force it to prefer those scenarios where
the gains are closer to the root.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.get_IVSD">
<code class="descname">get_IVSD</code><span class="sig-paren">(</span><em>output_gml=False</em>, <em>output_plot=False</em>, <em>tar=True</em>, <em>leading_model=False</em>, <em>mixed_threshold=0.0</em>, <em>evaluation='mwu'</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.get_IVSD" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate VSD on the basis of each item.</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.get_MLN">
<code class="descname">get_MLN</code><span class="sig-paren">(</span><em>glm</em>, <em>threshold=1</em>, <em>method='mr'</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.get_MLN" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute an Minimal Lateral Network for a given model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>glm</strong> : str</p>
<blockquote>
<div><p>The dictionary key for the gain-loss-model.</p>
</div></blockquote>
<p><strong>threshold</strong> : int (default=1)</p>
<blockquote>
<div><p>The threshold used to exclude edges.</p>
</div></blockquote>
<p><strong>method</strong> : str (default=&#8217;mr&#8217;)</p>
<blockquote class="last">
<div><p>Select the method for MLN calculation. Choose between:
* &#8220;mr&#8221;: majority-rule, multiple links are resolved by selecting</p>
<blockquote>
<div><p>those which occur most frequently</p>
</div></blockquote>
<ul class="simple">
<li>&#8220;td&#8221;: tree-distance, multiple links are resolved by selecting
those which are closest on the tree</li>
<li>&#8220;bc&#8221;: betweenness-centrality, multiple links are resolved by
selecting those which have the highest betweenness centrality</li>
</ul>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.get_MSN">
<code class="descname">get_MSN</code><span class="sig-paren">(</span><em>glm=''</em>, <em>fileformat='pdf'</em>, <em>external_edges=False</em>, <em>deep_nodes=False</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.get_MSN" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the Minimal Spatial Network.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>glm</strong> : str (default=&#8217;&#8216;)</p>
<blockquote>
<div><p>A string that encodes which model should be plotted.</p>
</div></blockquote>
<p><strong>filename</strong> : str</p>
<blockquote>
<div><p>The name of the file to which the plot shall be written.</p>
</div></blockquote>
<p><strong>fileformat</strong> : str</p>
<blockquote>
<div><p>The output format of the plot.</p>
</div></blockquote>
<p><strong>threshold</strong> : int (default=1)</p>
<blockquote>
<div><p>The threshold for the minimal amount of shared links that shall be
plotted.</p>
</div></blockquote>
<p><strong>usetex</strong> : bool (default=True)</p>
<blockquote class="last">
<div><p>Specify whether LaTeX shall be used for the plot.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.get_PDC">
<code class="descname">get_PDC</code><span class="sig-paren">(</span><em>glm</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.get_PDC" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate Patchily Distributed Cognates.</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.get_edge">
<code class="descname">get_edge</code><span class="sig-paren">(</span><em>glm</em>, <em>nodeA</em>, <em>nodeB</em>, <em>entries=''</em>, <em>msn=False</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.get_edge" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the edge data for a given gain-loss model.</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.get_stats">
<code class="descname">get_stats</code><span class="sig-paren">(</span><em>glm</em>, <em>subset=''</em>, <em>filename=''</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.get_stats" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate basic statistics for a given gain-loss model.</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.plot_ACS">
<code class="descname">plot_ACS</code><span class="sig-paren">(</span><em>glm</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.plot_ACS" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot a tree in which the node size correlates with the size of the ancestral node.</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.plot_GLS">
<code class="descname">plot_GLS</code><span class="sig-paren">(</span><em>glm</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.plot_GLS" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the inferred scenarios for a given model.</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.plot_MLN">
<code class="descname">plot_MLN</code><span class="sig-paren">(</span><em>glm=''</em>, <em>fileformat='pdf'</em>, <em>threshold=1</em>, <em>usetex=False</em>, <em>taxon_labels='taxon_short_labels'</em>, <em>alphat=False</em>, <em>alpha=0.75</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.plot_MLN" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the MLN with help of Matplotlib.</p>
<dl class="docutils">
<dt>glm</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str (default=&#8217;&#8216;)</span><dd>Identifier for the gain-loss model that is plotted. Defaults to the
model that had the best scores in terms of probability.</dd>
<dt>filename</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str (default=&#8217;&#8216;)</span><dd>If no filename is selected, the filename is identical with the
dataset.</dd>
<dt>fileformat</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">{&#8216;svg&#8217;,&#8217;png&#8217;,&#8217;jpg&#8217;,&#8217;pdf&#8217;} (default=&#8217;pdf&#8217;)</span><dd>Select the format of the output plot.</dd>
<dt>threshold</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int (default=1)</span><dd>Select the threshold for drawing lateral edges.</dd>
<dt>usetex</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">bool (default=True)</span><dd>Specify whether you want to use LaTeX to render plots.</dd>
<dt>colormap</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">{None matplotlib.cm}</span><dd>A <code class="xref py py-class docutils literal"><span class="pre">matplotlib.colormap</span></code> instance. If set to c{None}, this
defaults to <code class="xref py py-class docutils literal"><span class="pre">jet</span></code>.</dd>
<dt>taxon_labels</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str (default=&#8217;taxon.short_labels&#8217;)</span><dd>Specify the taxon labels that should be included in the plot.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.plot_MLN_3d">
<code class="descname">plot_MLN_3d</code><span class="sig-paren">(</span><em>glm=''</em>, <em>filename=''</em>, <em>fileformat='pdf'</em>, <em>threshold=1</em>, <em>usetex=True</em>, <em>colormap=None</em>, <em>taxon_labels='taxon_short_labels'</em>, <em>alphat=False</em>, <em>alpha=0.75</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.plot_MLN_3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the MLN with help of Matplotlib in 3d.</p>
<dl class="docutils">
<dt>glm</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str (default=&#8217;&#8216;)</span><dd>Identifier for the gain-loss model that is plotted. Defaults to the
model that had the best scores in terms of probability.</dd>
<dt>filename</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str (default=&#8217;&#8216;)</span><dd>If no filename is selected, the filename is identical with the
dataset.</dd>
<dt>fileformat</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">{&#8216;svg&#8217;,&#8217;png&#8217;,&#8217;jpg&#8217;,&#8217;pdf&#8217;} (default=&#8217;pdf&#8217;)</span><dd>Select the format of the output plot.</dd>
<dt>threshold</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int (default=1)</span><dd>Select the threshold for drawing lateral edges.</dd>
<dt>usetex</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">bool (default=True)</span><dd>Specify whether you want to use LaTeX to render plots.</dd>
<dt>colormap</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">{None matplotlib.cm}</span><dd>A <code class="xref py py-class docutils literal"><span class="pre">matplotlib.colormap</span></code> instance. If set to c{None}, this
defaults to <code class="xref py py-class docutils literal"><span class="pre">jet</span></code>.</dd>
<dt>taxon_labels</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str (default=&#8217;taxon.short_labels&#8217;)</span><dd>Specify the taxon labels that should be included in the plot.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.plot_MSN">
<code class="descname">plot_MSN</code><span class="sig-paren">(</span><em>glm=''</em>, <em>fileformat='pdf'</em>, <em>threshold=1</em>, <em>usetex=False</em>, <em>alphat=False</em>, <em>alpha=0.75</em>, <em>only=[]</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.plot_MSN" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot a minimal spatial network.</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.plot_concept_evolution">
<code class="descname">plot_concept_evolution</code><span class="sig-paren">(</span><em>glm</em>, <em>concept=''</em>, <em>fileformat='png'</em>, <em>**keywords</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.plot_concept_evolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the evolution of specific concepts along the reference tree.</p>
</dd></dl>

<dl class="method">
<dt id="lingpy.compare.phylogeny.PhyBo.plot_two_concepts">
<code class="descname">plot_two_concepts</code><span class="sig-paren">(</span><em>concept</em>, <em>cogA</em>, <em>cogB</em>, <em>labels={1: '1'</em>, <em>2: '2'</em>, <em>3: '3'</em>, <em>4: '4'}</em>, <em>tcolor={1: 'white'</em>, <em>2: 'black'</em>, <em>3: '0.5'</em>, <em>4: '0.1'}</em>, <em>filename='pdf'</em>, <em>fileformat='pdf'</em>, <em>threshold=1</em>, <em>usetex=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.PhyBo.plot_two_concepts" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the evolution of two concepts in space.</p>
<p class="rubric">Notes</p>
<p>This function may be useful to contrast patterns of different words in
geographic space.</p>
</dd></dl>

</dd></dl>

<dl class="attribute">
<dt id="lingpy.compare.phylogeny.TreBor">
<code class="descclassname">lingpy.compare.phylogeny.</code><code class="descname">TreBor</code><a class="headerlink" href="#lingpy.compare.phylogeny.TreBor" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#lingpy.compare.phylogeny.PhyBo" title="lingpy.compare.phylogeny.PhyBo"><code class="xref py py-class docutils literal"><span class="pre">PhyBo</span></code></a></p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.phylogeny.get_gls">
<code class="descclassname">lingpy.compare.phylogeny.</code><code class="descname">get_gls</code><span class="sig-paren">(</span><em>paps</em>, <em>taxa</em>, <em>tree</em>, <em>gpl=1</em>, <em>weights=(1</em>, <em>1)</em>, <em>push_gains=True</em>, <em>missing_data=0</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.phylogeny.get_gls" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate a gain-loss scenario.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>paps</strong> : list</p>
<blockquote>
<div><p>A list containing the presence-absence patterns for all leaves of the
reference tree. Presence is indicated by 1, and absence by 0. Missing
characters are indicated by -1.</p>
</div></blockquote>
<p><strong>taxa</strong> : list</p>
<blockquote>
<div><p>The list of taxa (leaves of the tree).</p>
</div></blockquote>
<p><strong>tree</strong> : str</p>
<blockquote>
<div><p>A tree in Newick-format. Taxon names should (of course) be identical
with the names in the list of taxa.</p>
</div></blockquote>
<p><strong>gpl</strong> : int</p>
<blockquote>
<div><p>Gains per lineage. Specify the maximal amount of gains per lineage. One
lineage is hereby defined as one path in the tree. If set to 0, only
one gain per lineage is allowed, if set to 1, one additional gain is
allowed, and so on. Use with care, since this will lead to larger
computation costs (more possibilities have to be taken care of) and can
also be quite unrealistic.</p>
</div></blockquote>
<p><strong>weights</strong> : tuple (default=(1,1))</p>
<blockquote>
<div><p>Specify the weights for gains and losses. Setting this parameter to
(2,1) will penalize gain events with 2 and loss events with 1.</p>
</div></blockquote>
<p><strong>push_gains</strong> : bool (default=True)</p>
<blockquote>
<div><p>Determine whether of a set of equally parsimonious patterns those
should be retained that show gains closer to the leaves of the tree or
not.</p>
</div></blockquote>
<p><strong>missing_data</strong> : int (default=0)</p>
<blockquote class="last">
<div><p>Determine how missing data should be represented. If set to 0
(default), missing data will be treated in the same way as absence
character states. If you want missing data to be accounted for in the
algorithm, set this parameter to -1.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>This is an enhanced version of the older approach to parsimony-based
gain-loss mapping. The algorithm is much faster than the previous one and
also written much clearer as to the code. In most tests I ran so far, it
also outperformed other approaches by finding more parsimonious solutions.</p>
</dd></dl>

</div>
<div class="section" id="module-lingpy.compare.strings">
<span id="lingpy-compare-strings-module"></span><h2>lingpy.compare.strings module<a class="headerlink" href="#module-lingpy.compare.strings" title="Permalink to this headline">¶</a></h2>
<p>Module provides various string similarity metrics.</p>
<dl class="function">
<dt id="lingpy.compare.strings.bidist1">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">bidist1</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.bidist1" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes bigram-based distance.</p>
<p class="rubric">Notes</p>
<p>The binary version.
Checks if two bigrams are equal or not.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.bidist2">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">bidist2</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.bidist2" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes bigram based distance.</p>
<p class="rubric">Notes</p>
<p>The comprehensive version of the
bigram distance.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.bidist3">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">bidist3</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.bidist3" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes bigram based distance.</p>
<p class="rubric">Notes</p>
<p>Computes the positional version of the
bigrams. Assigns a partial distance between two bigrams based on positional
similarity of bigrams.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.bisim1">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">bisim1</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.bisim1" title="Permalink to this definition">¶</a></dt>
<dd><p>computes the binary version of bigram similarity.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.bisim2">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">bisim2</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.bisim2" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes bigram similarity &#8220;the comprehensive version&#8221;.</p>
<p class="rubric">Notes</p>
<p>Computes the
number of common 1-grams between two n-grams.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.bisim3">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">bisim3</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.bisim3" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes bi-sim the positional version.</p>
<p class="rubric">Notes</p>
<p>The partial similarity between two
bigrams is defined as the number of matching 1-grams at each position.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.dice">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">dice</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.dice" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the Dice measure that measures the number of common bigrams.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.ident">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">ident</code><span class="sig-paren">(</span><em>a</em>, <em>b</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.ident" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the identity between two strings. If yes, returns 1, else, returns 0.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.jcd">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">jcd</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.jcd" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the bigram-based Jaccard Index.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.jcdn">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">jcdn</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.jcdn" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the bigram and trigram-based Jaccard Index</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.lcs">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">lcs</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.lcs" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the longest common subsequence between two strings.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.ldn">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">ldn</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.ldn" title="Permalink to this definition">¶</a></dt>
<dd><p>Basic Levenshtein distance without swap operation (all operations are equal costs).</p>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference internal" href="lingpy.align.html#lingpy.align.pairwise.edit_dist" title="lingpy.align.pairwise.edit_dist"><code class="xref py py-obj docutils literal"><span class="pre">lingpy.align.pairwise.edit_dist</span></code></a>, <a class="reference internal" href="#lingpy.compare.strings.ldn_swap" title="lingpy.compare.strings.ldn_swap"><code class="xref py py-obj docutils literal"><span class="pre">lingpy.compare.strings.ldn_swap</span></code></a></p>
</div>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.ldn_swap">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">ldn_swap</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.ldn_swap" title="Permalink to this definition">¶</a></dt>
<dd><p>Basic Levenshtein distance with swap operation included (identifies metathesis).</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.prefix">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">prefix</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.prefix" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the longest common prefix between two strings.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.tridist1">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">tridist1</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.tridist1" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes trigram-based distance.</p>
<p class="rubric">Notes</p>
<p>The binary version.
Checks if two trigrams are equal or not.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.tridist2">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">tridist2</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.tridist2" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes bigram based distance.</p>
<p class="rubric">Notes</p>
<p>The comprehensive version of the
bigram distance.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.tridist3">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">tridist3</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.tridist3" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes trigram based distance.</p>
<p class="rubric">Notes</p>
<p>Computes the positional version of the
trigrams. Assigns a partial distance between two trigrams based on positional
similarity of trigrams.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.trigram">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">trigram</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.trigram" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the number of common trigrams between two strings.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.trisim1">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">trisim1</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.trisim1" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the binary version of trigram similarity.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.trisim2">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">trisim2</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.trisim2" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes tri-sim &#8220;the comprehensive version&#8221;.</p>
<p class="rubric">Notes</p>
<p>Simply computes the number of common 1-grams between two n-grams instead of
calling LCS as should be done in <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Kondrak2005"><span class="pre">Kondrak2005</span></a></code> paper. Note that the
LCS for a trigram can be computed in O(n) time if we asssume that list
lookup is in constant time.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.trisim3">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">trisim3</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.trisim3" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes tri-sim the &#8220;positional version&#8221;.</p>
<p class="rubric">Notes</p>
<p>Simply computes the
number of matching 1-grams in each position.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.xdice">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">xdice</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.xdice" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the skip 1 character version of Dice.</p>
</dd></dl>

<dl class="function">
<dt id="lingpy.compare.strings.xxdice">
<code class="descclassname">lingpy.compare.strings.</code><code class="descname">xxdice</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>normalized=True</em><span class="sig-paren">)</span><a class="headerlink" href="#lingpy.compare.strings.xxdice" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the XXDice between two strings.</p>
<p class="rubric">Notes</p>
<p>Taken from <code class="docutils literal"><a class="reference external" href="http://lingulist.de/evobib/evobib.php?key=Brew1996"><span class="pre">Brew1996</span></a></code>.</p>
</dd></dl>

</div>
<div class="section" id="module-lingpy.compare">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-lingpy.compare" title="Permalink to this headline">¶</a></h2>
<p>Basic module for language comparison.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/lingpy-logo.svg" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">lingpy.compare package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-lingpy.compare.lexstat">lingpy.compare.lexstat module</a></li>
<li><a class="reference internal" href="#module-lingpy.compare.partial">lingpy.compare.partial module</a></li>
<li><a class="reference internal" href="#module-lingpy.compare.phylogeny">lingpy.compare.phylogeny module</a></li>
<li><a class="reference internal" href="#module-lingpy.compare.strings">lingpy.compare.strings module</a></li>
<li><a class="reference internal" href="#module-lingpy.compare">Module contents</a></li>
</ul>
</li>
</ul>

  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/reference/lingpy.compare.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
	<li><a href="../index.html">Home</a> |&nbsp;</li>
	<li><a href="../news.html">News</a> |&nbsp;</li>
	<li><a href="../intro.html">Introduction</a> |&nbsp;</li>
	<li><a href="../examples.html">Examples</a> |&nbsp;</li>
	<li><a href="../tutorial/index.html">Tutorial</a> |&nbsp;</li>
	<li><a href="../docu/index.html">Documentation</a> |&nbsp;</li>
	<li><a href="modules.html">Reference</a> |&nbsp;</li>
        <li><a href="../download.html">Download </a> </li>

 
      </ul>
    </div>
 <div id="footer" style="align-items:center;padding-top:5px;padding-left:0px;display:flex;justify-content:space-between;">

   <div>
     <a href="http://ssh.mpg.de"><img width="60px" src="../_static/minerva.png" alt="MPG-SSH" /></a>
   </div>
  <div>
    <a href="http://dfg.de/"><img width="80px" src="../_static/dfg_logo_schwarz.jpg" alt="DFG" /></a>
  </div>

  <div style="max-width:300px;">
    <p style="font-size:70%">Created using <a href="http://sphinx-doc.org">Sphinx</a>. Last updated
    on May 17, 2016<br>
      This work is licensed under a <a rel="license"
        href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_US">Creative
      Commons Attribution-NonCommercial 3.0 Unported License</a>.</p>
    <p>
      <a rel="license" href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_US">
        <img alt="Creative Commons License" style="border-width:0;width:100px;"
		    src="http://i.creativecommons.org/l/by-nc/3.0/88x31.png" /></a> </p>
  </div>

  <div>
    <a href="http://erc.europa.eu/"><img width="80px" src="http://quanthistling.info/theme/qhl/images/logo_erc.png" alt="ERC" /></a>
  </div>
  <div style="max-width:150px;text-align:right;">
    <a href="http://github.com/lingpy/lingpy/">Application source on</a> 
    <a href="https://github.com/"><img width="100px" src="../_static/GitHub_Logo.png" alt="github logo" /></a>
</div>
</div>

  </body>
</html>