"""A file to visually check the result of camera coordinate to robot base transformation

"""

# The MIT License (MIT)
#
# Copyright (c) 2016 GTRC.
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

import cv2
import os
import numpy as np
import json
import track_grid
import re
import compute_transformations
import argparse

def main():
    """
    Exposes :py:func:`check_transformation` to the commandline. Run with arg
    `-h` for more info.
    """
    # Parse in arguments
    parser = argparse.ArgumentParser(
        description="Visualize computed transformations")

    parser.add_argument("--r2c_calibration", type=str,
                        help='JSON file generated by compute_transformations',
                        default='transformation.json')

    parser.add_argument("--robot_data", type=str,
                        help="The filename of the robot poses in the images. "
                             "This file should be a json file with fields: "
                             "'time', 'tcp2robot', 'camera2grid'. 'tcp2robot' "
                             "and 'camera2grid' should be lists of lists, with "
                             "each individual list being a Rodrigues vector "
                             "(x,y,z,3 element rotation vector/axis-angle). "
                             "Linear distance must be consistent with each "
                             "other and the camera intrinsic and distortion "
                             "data (mm are recommended). Angular distances "
                             "must be in radians.",
                        default='correspondences.json')

    parser.add_argument("--image_folder", type=str,
                        help="The name of the folder to read images from",
                        default='input_images')

    parser.add_argument("--result_folder", type=str,
                        help="The name of the folder to save the output "
                             "images in",
                        default='output_images')

    parser.add_argument("--cam_calibration", type=str,
                        help="The JSON file holding the camera calibration "
                             "data as generated by: "
                             "https://pypi.python.org/pypi/camera_calibration/",
                        default='calibration.json')

    args = parser.parse_args()

    check_transformation(
        r2c_calibration=args.r2c_calibration,
        robot_data=args.robot_data,
        image_folder=args.image_folder,
        result_folder=args.result_folder,
        cam_calibration=args.cam_calibration
    )


def check_transformation(r2c_calibration, robot_data, image_folder,
                         result_folder, cam_calibration):
    """Plots transformed 3D world points onto camera image

    Args:
        r2c_calibration (str): JSON file generated by
                           compute_transformations
        robot_data (str): The filename of the robot poses in the images.
                          This file should be a json file with fields:
                          'time', 'tcp2robot', 'camera2grid'.
                          'tcp2robot' and 'camera2grid' should be lists
                          of lists, with each individual list being a
                          Rodrigues vector
                          (x,y,z,3 element rotation vector/axis-angle).
                          Linear distance must be consistent with each
                           other and the camera intrinsic and
                           distortion data (mm are recommended).
                           Angular distances must be in radians.
        image_folder (str): The name of the folder to read images from
        result_folder (str): The name of the folder to save the output images in
        cam_calibration (str): The JSON file holding the camera
                                  calibration data as generated by:
                                  https://pypi.python.org/pypi/camera_calibration/
    """
    if len(result_folder) and (result_folder[0] == '/' or
                                       result_folder[0] == '\\'):
        result_folder = result_folder[1:]
    if len(result_folder) and (result_folder[-1] == '/' or
                                       result_folder[-1] == '\\'):
        result_folder = result_folder[:-1]

    if len(image_folder) and (image_folder[0] == '/' or
                                      image_folder[0] == '\\'):
        image_folder = image_folder[1:]
    if len(image_folder) and (image_folder[-1] == '/' or
                                      image_folder[-1] == '\\'):
        image_folder = image_folder[:-1]

    with open(cam_calibration, 'r') as open_file:
        calib_dict = json.load(open_file)
        intrinsic = np.array(calib_dict['intrinsic'])
        distortion = np.array(calib_dict['distortion'])
        print("Loaded camera calibration data from {}".format(
            calib_dict['time']))

    with open(robot_data, 'r') as open_file:
        robot_dict = json.load(open_file)
        # nx6 arrays x,y,z,axis-angle:
        tcp2robot = robot_dict['tcp2robot']
        camera2target = robot_dict['camera2grid']
        print("Loaded calibration data from {}".format(
            robot_dict['time']))

    with open(r2c_calibration, 'r') as open_file:
        r2c_dict = json.load(open_file)
        # nx6 arrays x,y,z,axis-angle:
        tcp2target = r2c_dict['tcp2target']['Tmatrix']
        cam2rob = r2c_dict['cam2robot']['Tmatrix']
        print("Loaded calibration results from {}".format(r2c_dict['time']))

    target_directory = os.path.join(os.getcwd(), image_folder)
    directory_out = os.path.join(os.getcwd(), result_folder)
    file_names = os.listdir(target_directory)
    if not os.path.exists(directory_out):
        os.makedirs(directory_out)

    axis_length = 250
    axis = np.float32([[0, 0, 0], [axis_length, 0, 0], [0, axis_length, 0],
                       [0, 0, axis_length]]).reshape(-1, 3)

    number_found = 0

    for image_file in sort_nicely(file_names):
        image_file = os.path.join(target_directory, image_file)

        # Try to read in image as gray scale
        img = cv2.imread(image_file, 0)

        # If the image_file isn't an image, move on
        if img is not None:
            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
            labels = ['base_est', 'tcp_est', 'target_est', 'target_measured']
            tcp_est = np.matmul(cam2rob,
                                compute_transformations.vector2mat(
                                    tcp2robot[number_found]))
            target_est = np.matmul(tcp_est, tcp2target)
            coordinates = np.array([cam2rob, tcp_est, target_est, compute_transformations.vector2mat(camera2target[number_found])])
            for j in range(coordinates.shape[0]):
                cam2target = np.array(coordinates[j])
                rvec, jac = cv2.Rodrigues(cam2target[0:3,0:3])
                image_points, jac = cv2.projectPoints(axis, rvec,
                                                      cam2target[0:3, 3],
                                                      intrinsic, distortion)
                img = track_grid.draw_axes(image_raw=img,
                                           corners=image_points[0],
                                           image_points=image_points[1:],
                                           label=labels[j])
            cv2.imwrite(
                os.path.join(
                    result_folder, "result" + str(number_found) + ".jpg"), img)
            print("finished processing Image {}".format(image_file))
            number_found += 1
    print("Done processing all images")


# http://stackoverflow.com/questions/4623446/how-do-you-sort-files-numerically
def tryint(s):
    try:
        return int(s)
    except:
        return s


def alphanum_key(s):
    """ Turn a string into a list of string and number chunks.
        "z23a" -> ["z", 23, "a"]
    """
    return [tryint(c) for c in re.split('([0-9]+)', s)]


def sort_nicely(l):
    """ Sort the given list in the way that humans expect.
    """
    return sorted(l, key=alphanum_key)


if __name__ == "__main__":
    main()