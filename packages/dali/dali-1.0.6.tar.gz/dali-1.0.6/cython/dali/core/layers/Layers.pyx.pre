pyp
from preprocessor_utils import (
    typed_expression,
    typed_fexpression,
    typed_expression_args,
    typed_fexpression_args,
    typed_expression_args_with_types,
    typed_expression_list,
    type_repeat,
    type_frepeat,
    type_repeat_with_types,
)
ypy


cdef extern from "dali/layers/Layers.h" nogil:
    cdef cppclass CLayer "Layer" [T]:
        int hidden_size
        int input_size
        CMat[T] W
        CMat[T] b

        vector[CMat[T]] parameters() const
        # constructors
        CLayer()
        CLayer(int input_size, int hidden_size)
        CLayer(const CLayer& other, bint copy_w, bint copy_dw)

        CMat[T] activate(CMat[T]) except +
        CLayer[T] shallow_copy() const

    cdef cppclass CRNN "RNN" [T] nogil:
        int input_size
        int hidden_size
        int output_size

        CMat[T] Wx
        CMat[T] Wh
        CMat[T] b

        CRNN()
        CRNN(int input_size, int hidden_size)
        CRNN(int input_size, int hidden_size, int output_size)
        CRNN(CRNN[T]&, bool, bool)
        CMat[T] activate(CMat[T] input_vector, CMat[T] prev_hidden) except +
        CRNN[T] shallow_copy() const
        vector[CMat[T]] parameters() const

    cdef cppclass CStackedInputLayer "StackedInputLayer" [T] nogil:
        vector[int] input_sizes() const
        int hidden_size
        vector[CMat[T]] matrices
        CMat[T] b

        vector[CMat[T]] parameters() const
        CStackedInputLayer()
        CStackedInputLayer(vector[int] input_sizes, int output_size)
        CStackedInputLayer(const CStackedInputLayer& other, bint copy_w, bint copy_dw)

        CMat[T] activate(const vector[CMat[T]]&) except +
        CMat[T] activate(CMat[T]) except +
        CMat[T] activate(CMat[T], const vector[CMat[T]]&) except +

        CStackedInputLayer[T] shallow_copy() const


cdef class Layer:
    cdef void* layerinternal
    cdef np.NPY_TYPES dtypeinternal

    property dtype:
        def __get__(Layer self):
            return np.PyArray_DescrFromType(self.dtypeinternal)



pyprepeat PROPERTY_NAME in ['input_size', 'hidden_size',]
    property PROPERTY_NAME:
        def __get__(Layer self):
            pypinline typed_fexpression_args(pyp, ["self"],
                return DEREF_LAYER(self).PROPERTY_NAME
            ypy
ypyrepeat

pyprepeat PARAM_NAME in ['W', 'b']

    property PARAM_NAME:
        def __get__(Layer self):
            pypinline typed_fexpression_args(pyp, ["self"],
                return WRAP_MAT(DEREF_LAYER(self).PARAM_NAME)
            ypy
ypyrepeat

    def name_parameters(self, prefix):
        self.W.name = prefix + ".W"
        self.b.name = prefix + ".b"

    def __cinit__(Layer self, int input_size, int hidden_size, dtype=np.float32):
        self.layerinternal = NULL
        self.dtypeinternal = np.NPY_NOTYPE


        self.dtypeinternal = np.dtype(dtype).num
        pypinline typed_fexpression_args(pyp, ["self"],
            self.layerinternal = new CLayer[TYPE_NAME](input_size, hidden_size)
        ypy

    def __dealloc__(Layer self):
        self.free_internal()

    cdef free_internal(Layer self):
        pypinline type_frepeat(pyp,
        cdef CLayer[TYPE_NAME]* TYPED(ptr_internal)
        ypy
        if self.layerinternal != NULL:
            pypinline typed_fexpression_args(pyp, ["self"],
                TYPED(ptr_internal) = PTR_LAYER(self)
                with nogil:
                    del TYPED(ptr_internal)
            ypy
            self.layerinternal = NULL

    def activate(Layer self, Mat input_vector):
        assert self.dtypeinternal == input_vector.dtypeinternal, \
               "All arguments must be of the same type"
        pypinline type_frepeat(pyp,
        cdef CMat[TYPE_NAME] TYPED(out)
        ypy

        pypinline typed_fexpression(pyp,
            with nogil:
                TYPED(out) = DEREF_LAYER(self).activate(DEREF_MAT(input_vector))
            return WRAP_MAT(TYPED(out))
        ypy


    def shallow_copy(Layer self):
        cdef Layer copy = Layer(0,0)
        copy.free_internal()
        pypinline typed_fexpression(pyp,
            copy.layerinternal = new CLayer[TYPE_NAME](DEREF_LAYER(self), False, True)
        ypy
        return copy

    def parameters(Layer self):
        params = []
        pypinline type_frepeat(pyp,
        cdef CMat[TYPE_NAME]         TYPED(param)
        cdef vector[CMat[TYPE_NAME]] TYPED(param_vec)
        ypy
        pypinline typed_fexpression_args(pyp, ["self"],
            TYPED(param_vec) = DEREF_LAYER(self).parameters()
            for TYPED(param) in TYPED(param_vec):
                params.append(WRAP_MAT(TYPED(param)))
        ypy
        return params

    def __setstate__(Layer self, state):
        for param, saved_param in zip(self.parameters(), state["parameters"]):
            param.w = saved_param.w
        self.dtypeinternal = state["dtype"].num

    def __getstate__(Layer self):
        return {
            "parameters" : self.parameters(),
            "dtype" : self.dtype
        }

    def __reduce__(Layer self):
        return (
            self.__class__,
            (
                self.input_size,
                self.hidden_size,
            ), self.__getstate__(),
        )

    def __str__(self):
        return "<Layer in=%d, hidden=%d>" % (self.input_size, self.hidden_size)

    def __repr__(Layer self):
        return str(self)

pypinline type_repeat(pyp,
cdef void TYPED(copy_name_layer)(const CLayer[TYPE_NAME]& internal, const CLayer[TYPE_NAME]& output):
    TYPED(copy_name)(internal.W, output.W)
    TYPED(copy_name)(internal.b, output.b)
ypy

pypinline type_repeat(pyp,
cdef inline Layer TYPED(WrapLayer)(const CLayer[TYPE_NAME]& internal):
    cdef Layer output = Layer(0,0)
    output.free_internal()
    output.layerinternal = new CLayer[TYPE_NAME](internal, False, False)
    output.dtypeinternal = TYPE_NPYINTERNAL

    TYPED(copy_name_layer)(internal, DEREF_LAYER(output))

    return output
ypy


cdef class RNN:
    cdef void*        layerinternal
    cdef np.NPY_TYPES dtypeinternal

    property dtype:
        def __get__(RNN self):
            return np.PyArray_DescrFromType(self.dtypeinternal)

pyprepeat PROPERTY_NAME in ['input_size', 'hidden_size', 'output_size']
    property PROPERTY_NAME:
        def __get__(RNN self):
            pypinline typed_fexpression(pyp,
                return DEREF_RNN(self).PROPERTY_NAME
            ypy
ypyrepeat

pyprepeat PARAM_NAME in ['Wx', 'Wh', 'b']

    property PARAM_NAME:
        def __get__(RNN self):
            pypinline typed_fexpression(pyp,
                return WRAP_MAT(DEREF_RNN(self).PARAM_NAME)
            ypy
ypyrepeat

    def name_parameters(self, prefix):
        self.Wx.name = prefix + ".Wx"
        self.Wh.name = prefix + ".Wh"
        self.b.name = prefix + ".b"


    def __cinit__(self, int input_size, int hidden_size, output_size = None, dtype=np.float32):
        self.layerinternal = NULL
        self.dtypeinternal = np.NPY_NOTYPE

        if output_size is None:
            output_size = hidden_size
        assert(input_size > -1 and hidden_size > -1 and output_size > -1), "Only positive dimensions may be used."
        cdef int out_size = output_size

        self.dtypeinternal = np.dtype(dtype).num

        pypinline typed_fexpression_args(pyp, ["<RNN>self"],
            self.layerinternal = new CRNN[TYPE_NAME](input_size, hidden_size, out_size)
        ypy

    def __dealloc__(RNN self):
        self.free_internal()

    cdef free_internal(RNN self):
        pypinline type_frepeat(pyp,
        cdef CRNN[TYPE_NAME]* TYPED(ptr_internal)
        ypy
        if self.layerinternal != NULL:
            pypinline typed_fexpression(pyp,
                TYPED(ptr_internal) = PTR_RNN(self)
                with nogil:
                    del TYPED(ptr_internal)
            ypy
            self.layerinternal = NULL



    def __setstate__(RNN self, state):
        for param, saved_param in zip(self.parameters(), state["parameters"]):
            param.w = saved_param.w
        self.dtypeinternal = state["dtype"].num


    def __getstate__(self):
        return {
            "parameters" : self.parameters(),
            "dtype" : self.dtype
        }

    def __reduce__(self):
        return (
            self.__class__,
            (
                self.input_size,
                self.hidden_size,
                self.output_size
            ), self.__getstate__(),
        )


    def activate(RNN self, Mat input_vector,  Mat prev_hidden):
        assert self.dtypeinternal == input_vector.dtypeinternal and \
               self.dtypeinternal == prev_hidden.dtypeinternal, \
               "All arguments must be of the same type"
        pypinline type_frepeat(pyp,
        cdef CMat[TYPE_NAME] TYPED(out)
        ypy

        pypinline typed_fexpression(pyp,
            with nogil:
                TYPED(out) = DEREF_RNN(self).activate(DEREF_MAT(input_vector), DEREF_MAT(prev_hidden))
            return WRAP_MAT(TYPED(out))
        ypy


    def shallow_copy(RNN self):
        cdef RNN copy = RNN(0,0)
        copy.free_internal()
        pypinline typed_fexpression(pyp,
            copy.layerinternal = new CRNN[TYPE_NAME](DEREF_RNN(self), False, True)
        ypy
        return copy

    def parameters(RNN self):
        params = []
        pypinline type_frepeat(pyp,
        cdef CMat[TYPE_NAME]         TYPED(param)
        cdef vector[CMat[TYPE_NAME]] TYPED(param_vec)

        ypy
        pypinline typed_fexpression(pyp,
            TYPED(param_vec) = DEREF_RNN(self).parameters()
            for TYPED(param) in TYPED(param_vec):
                params.append(WRAP_MAT(TYPED(param)))
        ypy
        return params


    def __str__(self):
        return "<RNN in=%d, hidden=%d out=%d>" % (self.input_size, self.hidden_size, self.output_size)

    def __repr__(Layer self):
        return str(self)


cdef class StackedInputLayer:
    cdef void* layerinternal
    cdef np.NPY_TYPES dtypeinternal

    property dtype:
        def __get__(StackedInputLayer self):
            return np.PyArray_DescrFromType(self.dtypeinternal)


    property input_sizes:
        def __get__(StackedInputLayer self):
            pypinline typed_fexpression(pyp,
                return DEREF_STACKEDLAYER(self).input_sizes()
            ypy

    property hidden_size:
        def __get__(StackedInputLayer self):
            pypinline typed_fexpression(pyp,
                return DEREF_STACKEDLAYER(self).hidden_size
            ypy

    property matrices:
        def __get__(StackedInputLayer self):
            cdef int i
            params = []
            pypinline typed_fexpression(pyp,
                for i in range(DEREF_STACKEDLAYER(self).matrices.size()):
                    params.append(WRAP_MAT(DEREF_STACKEDLAYER(self).matrices[i]))
            ypy
            return params

    property b:
        def __get__(StackedInputLayer self):
            pypinline typed_fexpression(pyp,
                return WRAP_MAT(DEREF_STACKEDLAYER(self).b)
            ypy

    def name_parameters(self, prefix):
        for matidx, matrix in enumerate(self.matrices):
            matrix.name = prefix + ".matrices[%d]" % (matidx,)
        self.b.name = prefix + ".b"

    def __cinit__(StackedInputLayer self, list input_sizes, int hidden_size, dtype=np.float32):
        self.layerinternal = NULL
        self.dtypeinternal = np.NPY_NOTYPE

        self.dtypeinternal = np.dtype(dtype).num

        pypinline typed_fexpression(pyp,
            self.layerinternal = new CStackedInputLayer[TYPE_NAME](<vector[int]>input_sizes, hidden_size)
        ypy

    def __dealloc__(StackedInputLayer self):
        self.free_internal()

    cdef free_internal(StackedInputLayer self):
        pypinline type_frepeat(pyp,
        cdef CStackedInputLayer[TYPE_NAME]* TYPED(ptr_internal)
        ypy
        if self.layerinternal != NULL:
            pypinline typed_fexpression(pyp,
                TYPED(ptr_internal) = PTR_STACKEDLAYER(self)
                with nogil:
                    del TYPED(ptr_internal)
            ypy
            self.layerinternal = NULL

    def __setstate__(StackedInputLayer self, state):
        for param, saved_param in zip(self.parameters(), state["parameters"]):
            param.w = saved_param.w
            self.dtypeinternal = state["dtype"].num

    def __getstate__(self):
        return {
            "parameters" : self.parameters(),
            "dtype" : self.dtype,
        }

    def __reduce__(self):
        return (
            self.__class__,
            (
                self.input_sizes,
                self.hidden_size
            ), self.__getstate__(),
        )

    def activate(StackedInputLayer self, input_vectors):
        pypinline type_frepeat(pyp,
        cdef vector[CMat[TYPE_NAME]]  TYPED(input_vec)
        cdef CMat[TYPE_NAME]          TYPED(input_mat)
        cdef CMat[TYPE_NAME]          TYPED(out)
        ypy

        if type(input_vectors) is Mat:
            assert (<Mat>input_vectors).dtypeinternal == self.dtypeinternal, \
                    "input mat must be of the same type as StackedInputLayer"

            pypinline typed_fexpression_args(pyp, ["self"],
                TYPED(input_mat) = DEREF_MAT(input_vectors)
                with nogil:
                    TYPED(out) = DEREF_STACKEDLAYER(self).activate(TYPED(input_mat))
                return WRAP_MAT(TYPED(out))
            ypy
        elif type(input_vectors) == list:
            for v in input_vectors:
                assert type(v) == Mat, "Matrices required for Stacked Input Layer"
                assert (<Mat>v).dtypeinternal == self.dtypeinternal, "All arguments must have the same type."


            pypinline typed_fexpression_args(pyp, ["self"],
                TYPED(input_vec).clear()
                for inpt in input_vectors:
                    TYPED(input_vec).push_back(DEREF_MAT(inpt))
                with nogil:
                    TYPED(out) = DEREF_STACKEDLAYER(self).activate(TYPED(input_vec))
                return WRAP_MAT(TYPED(out))
            ypy
        else:
            raise TypeError("activate takes a list of Mat or single Mat as input.")

    def shallow_copy(StackedInputLayer self):
        cdef StackedInputLayer copy = StackedInputLayer(0,0)
        copy.free_internal()
        pypinline typed_fexpression_args(pyp, ["self"],
            copy.layerinternal = new CStackedInputLayer[TYPE_NAME](DEREF_STACKEDLAYER(self), False, True)
        ypy
        return copy


    def parameters(StackedInputLayer self):
        params = []
        pypinline type_frepeat(pyp,
        cdef CMat[TYPE_NAME]         TYPED(param)
        cdef vector[CMat[TYPE_NAME]] TYPED(param_vec)

        ypy
        pypinline typed_fexpression_args(pyp, ["self"],
            TYPED(param_vec) = DEREF_STACKEDLAYER(self).parameters()
            for TYPED(param) in TYPED(param_vec):
                params.append(WRAP_MAT(TYPED(param)))
        ypy
        return params

    def __str__(self):
        return "<StackedInputLayer in=%s, out=%d>" % (str(self.input_sizes), self.hidden_size)

    def __repr__(StackedInputLayer self):
        return str(self)

pypinline type_repeat(pyp,
cdef void TYPED(copy_name_stackedlayer)(const CStackedInputLayer[TYPE_NAME]& internal, const CStackedInputLayer[TYPE_NAME]& output):
    for i in range(internal.matrices.size()):
        TYPED(copy_name)(internal.matrices[i], output.matrices[i])
    TYPED(copy_name)(internal.b, output.b)
ypy


pypinline type_repeat(pyp,
cdef inline StackedInputLayer TYPED(WrapStackedLayer)(const CStackedInputLayer[TYPE_NAME]& internal):
    cdef StackedInputLayer output = StackedInputLayer([0],0)
    output.free_internal()
    output.layerinternal = new CStackedInputLayer[TYPE_NAME](internal, False, False)
    output.dtypeinternal = TYPE_NPYINTERNAL

    TYPED(copy_name_stackedlayer)(internal, DEREF_STACKEDLAYER(output))

    return output
ypy
